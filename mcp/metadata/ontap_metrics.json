{
  "aggr_disk_busy": "The utilization percent of the disk. aggr_disk_busy is [disk_busy](#disk_busy) aggregated by `aggr`.",
  "aggr_disk_capacity": "Disk capacity in MB. aggr_disk_capacity is [disk_capacity](#disk_capacity) aggregated by `aggr`.",
  "aggr_disk_cp_read_chain": "Average number of blocks transferred in each consistency point read operation during a CP. aggr_disk_cp_read_chain is [disk_cp_read_chain](#disk_cp_read_chain) aggregated by `aggr`.",
  "aggr_disk_cp_read_latency": "Average latency per block in microseconds for consistency point read operations. aggr_disk_cp_read_latency is [disk_cp_read_latency](#disk_cp_read_latency) aggregated by `aggr`.",
  "aggr_disk_cp_reads": "Number of disk read operations initiated each second for consistency point processing. aggr_disk_cp_reads is [disk_cp_reads](#disk_cp_reads) aggregated by `aggr`.",
  "aggr_disk_io_pending": "Average number of I/Os issued to the disk for which we have not yet received the response. aggr_disk_io_pending is [disk_io_pending](#disk_io_pending) aggregated by `aggr`.",
  "aggr_disk_io_queued": "Number of I/Os queued to the disk but not yet issued. aggr_disk_io_queued is [disk_io_queued](#disk_io_queued) aggregated by `aggr`.",
  "aggr_disk_max_busy": "The utilization percent of the disk. aggr_disk_max_busy is the maximum of [disk_busy](#disk_busy) for label `aggr`.",
  "aggr_disk_max_capacity": "Disk capacity in MB. aggr_disk_max_capacity is the maximum of [disk_capacity](#disk_capacity) for label `aggr`.",
  "aggr_disk_max_cp_read_chain": "Average number of blocks transferred in each consistency point read operation during a CP. aggr_disk_max_cp_read_chain is the maximum of [disk_cp_read_chain](#disk_cp_read_chain) for label `aggr`.",
  "aggr_disk_max_cp_read_latency": "Average latency per block in microseconds for consistency point read operations. aggr_disk_max_cp_read_latency is the maximum of [disk_cp_read_latency](#disk_cp_read_latency) for label `aggr`.",
  "aggr_disk_max_cp_reads": "Number of disk read operations initiated each second for consistency point processing. aggr_disk_max_cp_reads is the maximum of [disk_cp_reads](#disk_cp_reads) for label `aggr`.",
  "aggr_disk_max_io_pending": "Average number of I/Os issued to the disk for which we have not yet received the response. aggr_disk_max_io_pending is the maximum of [disk_io_pending](#disk_io_pending) for label `aggr`.",
  "aggr_disk_max_io_queued": "Number of I/Os queued to the disk but not yet issued. aggr_disk_max_io_queued is the maximum of [disk_io_queued](#disk_io_queued) for label `aggr`.",
  "aggr_disk_max_total_data": "Total throughput for user operations per second. aggr_disk_max_total_data is the maximum of [disk_total_data](#disk_total_data) for label `aggr`.",
  "aggr_disk_max_total_transfers": "Total number of disk operations involving data transfer initiated per second. aggr_disk_max_total_transfers is the maximum of [disk_total_transfers](#disk_total_transfers) for label `aggr`.",
  "aggr_disk_max_user_read_blocks": "Number of blocks transferred for user read operations per second. aggr_disk_max_user_read_blocks is the maximum of [disk_user_read_blocks](#disk_user_read_blocks) for label `aggr`.",
  "aggr_disk_max_user_read_chain": "Average number of blocks transferred in each user read operation. aggr_disk_max_user_read_chain is the maximum of [disk_user_read_chain](#disk_user_read_chain) for label `aggr`.",
  "aggr_disk_max_user_read_latency": "Average latency per block in microseconds for user read operations. aggr_disk_max_user_read_latency is the maximum of [disk_user_read_latency](#disk_user_read_latency) for label `aggr`.",
  "aggr_disk_max_user_reads": "Number of disk read operations initiated each second for retrieving data or metadata associated with user requests. aggr_disk_max_user_reads is the maximum of [disk_user_reads](#disk_user_reads) for label `aggr`.",
  "aggr_disk_max_user_write_blocks": "Number of blocks transferred for user write operations per second. aggr_disk_max_user_write_blocks is the maximum of [disk_user_write_blocks](#disk_user_write_blocks) for label `aggr`.",
  "aggr_disk_max_user_write_chain": "Average number of blocks transferred in each user write operation. aggr_disk_max_user_write_chain is the maximum of [disk_user_write_chain](#disk_user_write_chain) for label `aggr`.",
  "aggr_disk_max_user_write_latency": "Average latency per block in microseconds for user write operations. aggr_disk_max_user_write_latency is the maximum of [disk_user_write_latency](#disk_user_write_latency) for label `aggr`.",
  "aggr_disk_max_user_writes": "Number of disk write operations initiated each second for storing data or metadata associated with user requests. aggr_disk_max_user_writes is the maximum of [disk_user_writes](#disk_user_writes) for label `aggr`.",
  "aggr_disk_total_data": "Total throughput for user operations per second. aggr_disk_total_data is [disk_total_data](#disk_total_data) aggregated by `aggr`.",
  "aggr_disk_total_transfers": "Total number of disk operations involving data transfer initiated per second. aggr_disk_total_transfers is [disk_total_transfers](#disk_total_transfers) aggregated by `aggr`.",
  "aggr_disk_user_read_blocks": "Number of blocks transferred for user read operations per second. aggr_disk_user_read_blocks is [disk_user_read_blocks](#disk_user_read_blocks) aggregated by `aggr`.",
  "aggr_disk_user_read_chain": "Average number of blocks transferred in each user read operation. aggr_disk_user_read_chain is [disk_user_read_chain](#disk_user_read_chain) aggregated by `aggr`.",
  "aggr_disk_user_read_latency": "Average latency per block in microseconds for user read operations. aggr_disk_user_read_latency is [disk_user_read_latency](#disk_user_read_latency) aggregated by `aggr`.",
  "aggr_disk_user_reads": "Number of disk read operations initiated each second for retrieving data or metadata associated with user requests. aggr_disk_user_reads is [disk_user_reads](#disk_user_reads) aggregated by `aggr`.",
  "aggr_disk_user_write_blocks": "Number of blocks transferred for user write operations per second. aggr_disk_user_write_blocks is [disk_user_write_blocks](#disk_user_write_blocks) aggregated by `aggr`.",
  "aggr_disk_user_write_chain": "Average number of blocks transferred in each user write operation. aggr_disk_user_write_chain is [disk_user_write_chain](#disk_user_write_chain) aggregated by `aggr`.",
  "aggr_disk_user_write_latency": "Average latency per block in microseconds for user write operations. aggr_disk_user_write_latency is [disk_user_write_latency](#disk_user_write_latency) aggregated by `aggr`.",
  "aggr_disk_user_writes": "Number of disk write operations initiated each second for storing data or metadata associated with user requests. aggr_disk_user_writes is [disk_user_writes](#disk_user_writes) aggregated by `aggr`.",
  "aggr_efficiency_savings": "Space saved by storage efficiencies (logical_used - used)",
  "aggr_efficiency_savings_wo_snapshots": "Space saved by storage efficiencies (logical_used - used)",
  "aggr_efficiency_savings_wo_snapshots_flexclones": "Space saved by storage efficiencies (logical_used - used)",
  "aggr_hybrid_cache_size_total": "Total usable space in bytes of SSD cache. Only provided when hybrid_cache.enabled is 'true'.",
  "aggr_hybrid_disk_count": "Number of disks used in the cache tier of the aggregate. Only provided when hybrid_cache.enabled is 'true'.",
  "aggr_inode_files_private_used": "Number of system metadata files used. If the referenced file system is restricted or offline, a value of 0 is returned.This is an advanced property; there is an added computational cost to retrieving its value. The field is not populated for either a collection GET or an instance GET unless it is explicitly requested using the \u003ci\u003efields\u003c/i\u003e query parameter containing either footprint or **.",
  "aggr_inode_files_total": "Maximum number of user-visible files that this referenced file system can currently hold. If the referenced file system is restricted or offline, a value of 0 is returned.",
  "aggr_inode_files_used": "Number of user-visible files used in the referenced file system. If the referenced file system is restricted or offline, a value of 0 is returned.",
  "aggr_inode_inodefile_private_capacity": "Number of files that can currently be stored on disk for system metadata files. This number will dynamically increase as more system files are created.This is an advanced property; there is an added computational cost to retrieving its value. The field is not populated for either a collection GET or an instance GET unless it is explicitly requested using the \u003ci\u003efields\u003c/i\u003e query parameter containing either footprint or **.",
  "aggr_inode_inodefile_public_capacity": "Number of files that can currently be stored on disk for user-visible files.  This number will dynamically increase as more user-visible files are created.This is an advanced property; there is an added computational cost to retrieving its value. The field is not populated for either a collection GET or an instance GET unless it is explicitly requested using the \u003ci\u003efields\u003c/i\u003e query parameter containing either footprint or **.",
  "aggr_inode_maxfiles_available": "The count of the maximum number of user-visible files currently allowable on the referenced file system.",
  "aggr_inode_maxfiles_possible": "The largest value to which the maxfiles-available parameter can be increased by reconfiguration, on the referenced file system.",
  "aggr_inode_maxfiles_used": "The number of user-visible files currently in use on the referenced file system.",
  "aggr_inode_used_percent": "The percentage of disk space currently in use based on user-visible file count on the referenced file system.",
  "aggr_labels": "This metric provides information about Aggregate",
  "aggr_logical_used_wo_snapshots": "Logical used",
  "aggr_logical_used_wo_snapshots_flexclones": "Logical used",
  "aggr_new_status": "This metric indicates a value of 1 if the aggregate state is online (indicating the aggregate is operational) and a value of 0 for any other state.",
  "aggr_object_store_logical_used": "Logical space usage of aggregates in the attached object store.",
  "aggr_object_store_physical_used": "Physical space usage of aggregates in the attached object store.",
  "aggr_other_data": "Performance metric for other I/O operations. Other I/O operations can be metadata operations, such as directory lookups and so on.",
  "aggr_other_latency": "Performance metric for other I/O operations. Other I/O operations can be metadata operations, such as directory lookups and so on.",
  "aggr_other_ops": "Performance metric for other I/O operations. Other I/O operations can be metadata operations, such as directory lookups and so on.",
  "aggr_physical_used_wo_snapshots": "Total Data Reduction Physical Used Without Snapshots",
  "aggr_physical_used_wo_snapshots_flexclones": "Total Data Reduction Physical Used without snapshots and flexclones",
  "aggr_power": "Power consumed by aggregate in Watts.",
  "aggr_primary_disk_count": "Number of disks used in the aggregate. This includes parity disks, but excludes disks in the hybrid cache.",
  "aggr_raid_disk_count": "Number of disks in the aggregate.",
  "aggr_raid_plex_count": "Number of plexes in the aggregate",
  "aggr_raid_size": "Option to specify the maximum number of disks that can be included in a RAID group.",
  "aggr_read_data": "Performance metric for read I/O operations.",
  "aggr_read_latency": "Performance metric for read I/O operations.",
  "aggr_read_ops": "Performance metric for read I/O operations.",
  "aggr_snapshot_files_total": "Total files allowed in snapshots",
  "aggr_snapshot_files_used": "Total files created in snapshots",
  "aggr_snapshot_inode_used_percent": "The percentage of disk space currently in use based on user-visible file (inode) count on the referenced file system.",
  "aggr_snapshot_maxfiles_available": "Maximum files available for snapshots",
  "aggr_snapshot_maxfiles_possible": "The largest value to which the maxfiles-available parameter can be increased by reconfiguration, on the referenced file system.",
  "aggr_snapshot_maxfiles_used": "Files in use by snapshots",
  "aggr_snapshot_reserve_percent": "Percentage of space reserved for snapshots",
  "aggr_snapshot_size_available": "Available space for snapshots in bytes",
  "aggr_snapshot_size_total": "Total space for snapshots in bytes",
  "aggr_snapshot_size_used": "Space used by snapshots in bytes",
  "aggr_snapshot_used_percent": "Percentage of disk space used by snapshots",
  "aggr_space_available": "Space available in bytes.",
  "aggr_space_capacity_tier_used": "Used space in bytes in the cloud store. Only applicable for aggregates with a cloud store tier.",
  "aggr_space_data_compacted_count": "Amount of compacted data in bytes.",
  "aggr_space_data_compaction_saved": "Space saved in bytes by compacting the data.",
  "aggr_space_data_compaction_saved_percent": "Percentage saved by compacting the data.",
  "aggr_space_performance_tier_inactive_user_data": "The size that is physically used in the block storage and has a cold temperature, in bytes. This property is only supported if the aggregate is either attached to a cloud store or can be attached to a cloud store.This is an advanced property; there is an added computational cost to retrieving its value. The field is not populated for either a collection GET or an instance GET unless it is explicitly requested using the \u003ci\u003efields\u003c/i\u003e query parameter containing either block_storage.inactive_user_data or **.",
  "aggr_space_performance_tier_inactive_user_data_percent": "The percentage of inactive user data in the block storage. This property is only supported if the aggregate is either attached to a cloud store or can be attached to a cloud store.This is an advanced property; there is an added computational cost to retrieving its value. The field is not populated for either a collection GET or an instance GET unless it is explicitly requested using the \u003ci\u003efields\u003c/i\u003e query parameter containing either block_storage.inactive_user_data_percent or **.",
  "aggr_space_performance_tier_used": "A summation of volume footprints (including volume guarantees), in bytes. This includes all of the volume footprints in the block_storage tier and the cloud_storage tier.This is an advanced property; there is an added computational cost to retrieving its value. The field is not populated for either a collection GET or an instance GET unless it is explicitly requested using the \u003ci\u003efields\u003c/i\u003e query parameter containing either footprint or **.",
  "aggr_space_performance_tier_used_percent": "A summation of volume footprints inside the aggregate,as a percentage. A volume's footprint is the amount of space being used for the volume in the aggregate.",
  "aggr_space_physical_used": "Total physical used size of an aggregate in bytes.",
  "aggr_space_physical_used_percent": "Physical used percentage.",
  "aggr_space_reserved": "The total disk space in bytes that is reserved on the referenced file system. The reserved space is already counted in the used space, so this element can be used to see what portion of the used space represents space reserved for future use.",
  "aggr_space_sis_saved": "Amount of space saved in bytes by storage efficiency.",
  "aggr_space_sis_saved_percent": "Percentage of space saved by storage efficiency.",
  "aggr_space_sis_shared_count": "Amount of shared bytes counted by storage efficiency.",
  "aggr_space_total": "Total usable space in bytes, not including WAFL reserve and aggregate snapshot reserve.",
  "aggr_space_used": "Space used or reserved in bytes. Includes volume guarantees and aggregate metadata.",
  "aggr_space_used_percent": "The percentage of disk space currently in use on the referenced file system",
  "aggr_total_data": "Performance metric aggregated over all types of I/O operations.",
  "aggr_total_latency": "Performance metric aggregated over all types of I/O operations.",
  "aggr_total_logical_used": "Logical used",
  "aggr_total_ops": "Performance metric aggregated over all types of I/O operations.",
  "aggr_total_physical_used": "Total Physical Used",
  "aggr_volume_count": "The aggregate's volume count, which includes both FlexVols and FlexGroup constituents.",
  "aggr_write_data": "Performance metric for write I/O operations.",
  "aggr_write_latency": "Performance metric for write I/O operations.",
  "aggr_write_ops": "Performance metric for write I/O operations.",
  "cifs_session_connection_count": "A counter used to track requests that are sent to the volumes to the node.",
  "cifs_session_idle_duration": "Specifies an ISO-8601 format of date and time used to retrieve the idle time duration in hours, minutes, and seconds format.",
  "cifs_session_labels": "This metric provides information about CIFSSession",
  "cifs_share_labels": "This metric provides information about CIFSShare",
  "cloud_target_labels": "This metric provides information about CloudTarget",
  "cloud_target_used": "The amount of cloud space used by all the aggregates attached to the target, in bytes. This field is only populated for FabricPool targets. The value is recalculated once every 5 minutes.",
  "cluster_new_status": "It is an indicator of the overall health status of the cluster, with a value of 1 indicating a healthy status and a value of 0 indicating an unhealthy status.",
  "cluster_other_data": "Performance metric for other I/O operations. Other I/O operations can be metadata operations, such as directory lookups and so on.",
  "cluster_other_latency": "Performance metric for other I/O operations. Other I/O operations can be metadata operations, such as directory lookups and so on.",
  "cluster_other_ops": "Performance metric for other I/O operations. Other I/O operations can be metadata operations, such as directory lookups and so on.",
  "cluster_peer_labels": "This metric provides information about ClusterPeer",
  "cluster_peer_non_encrypted": "This metric indicates a value of 1 if the cluster peer encryption state is none (indicating the connection is not encrypted) and a value of 0 for any other state.",
  "cluster_read_data": "Performance metric for read I/O operations.",
  "cluster_read_latency": "Performance metric for read I/O operations.",
  "cluster_read_ops": "Performance metric for read I/O operations.",
  "cluster_schedule_labels": "This metric provides information about ClusterSchedule",
  "cluster_software_status": "Displays the software job with its status.",
  "cluster_software_update": "Displays the software update phase with its status.",
  "cluster_software_validation": "Displays the software pre-validation checks with their status.",
  "cluster_space_available": "Available space across the cluster.",
  "cluster_subsystem_new_status": "This metric indicates a value of 1 if the subsystem health is ok (indicating the subsystem is operational) and a value of 0 for any other health status.",
  "cluster_subsystem_outstanding_alerts": "Number of outstanding alerts",
  "cluster_subsystem_suppressed_alerts": "Number of suppressed alerts",
  "cluster_tags": "Displays tags at the cluster level.",
  "cluster_total_data": "Performance metric aggregated over all types of I/O operations.",
  "cluster_total_latency": "Performance metric aggregated over all types of I/O operations.",
  "cluster_total_ops": "Performance metric aggregated over all types of I/O operations.",
  "cluster_write_data": "Performance metric for write I/O operations.",
  "cluster_write_latency": "Performance metric for write I/O operations.",
  "cluster_write_ops": "Performance metric for write I/O operations.",
  "copy_manager_bce_copy_count_curr": "Current number of copy requests being processed by the Block Copy Engine.",
  "copy_manager_kb_copied": "Sum of kilo-bytes copied.",
  "copy_manager_ocs_copy_count_curr": "Current number of copy requests being processed by the ONTAP copy subsystem.",
  "copy_manager_sce_copy_count_curr": "Current number of copy requests being processed by the System Continuous Engineering.",
  "copy_manager_spince_copy_count_curr": "Current number of copy requests being processed by the SpinCE.",
  "disk_busy": "The utilization percent of the disk",
  "disk_bytes_per_sector": "Bytes per sector.",
  "disk_capacity": "Disk capacity in MB",
  "disk_cp_read_chain": "Average number of blocks transferred in each consistency point read operation during a CP",
  "disk_cp_read_latency": "Average latency per block in microseconds for consistency point read operations",
  "disk_cp_reads": "Number of disk read operations initiated each second for consistency point processing",
  "disk_io_pending": "Average number of I/Os issued to the disk for which we have not yet received the response",
  "disk_io_queued": "Number of I/Os queued to the disk but not yet issued",
  "disk_labels": "This metric provides information about Disk",
  "disk_new_status": "This metric indicates a value of 1 if the disk is not in an outage (i.e., the outage label is empty) and a value of 0 if the shelf is in an outage.",
  "disk_power_on_hours": "Hours powered on.",
  "disk_sectors": "Number of sectors on the disk.",
  "disk_stats_average_latency": "Average I/O latency across all active paths, in milliseconds.",
  "disk_stats_io_kbps": "Total Disk Throughput in KBPS Across All Active Paths",
  "disk_stats_sectors_read": "Number of Sectors Read",
  "disk_stats_sectors_written": "Number of Sectors Written",
  "disk_total_data": "Total throughput for user operations per second",
  "disk_total_transfers": "Total number of disk operations involving data transfer initiated per second",
  "disk_uptime": "Number of seconds the drive has been powered on",
  "disk_usable_size": "Usable size of each disk, in bytes.",
  "disk_user_read_blocks": "Number of blocks transferred for user read operations per second",
  "disk_user_read_chain": "Average number of blocks transferred in each user read operation",
  "disk_user_read_latency": "Average latency per block in microseconds for user read operations",
  "disk_user_reads": "Number of disk read operations initiated each second for retrieving data or metadata associated with user requests",
  "disk_user_write_blocks": "Number of blocks transferred for user write operations per second",
  "disk_user_write_chain": "Average number of blocks transferred in each user write operation",
  "disk_user_write_latency": "Average latency per block in microseconds for user write operations",
  "disk_user_writes": "Number of disk write operations initiated each second for storing data or metadata associated with user requests",
  "ems_destination_labels": "This metric provides information about EmsDestination",
  "ems_events": "Indicates EMS events that have occurred in the ONTAP as configured in the ems.yaml.",
  "environment_sensor_average_ambient_temperature": "Average temperature of all ambient sensors for node in Celsius.",
  "environment_sensor_average_fan_speed": "Average fan speed for node in rpm.",
  "environment_sensor_average_temperature": "Average temperature of all non-ambient sensors for node in Celsius.",
  "environment_sensor_max_fan_speed": "Maximum fan speed for node in rpm.",
  "environment_sensor_max_temperature": "Maximum temperature of all non-ambient sensors for node in Celsius.",
  "environment_sensor_min_ambient_temperature": "Minimum temperature of all ambient sensors for node in Celsius.",
  "environment_sensor_min_fan_speed": "Minimum fan speed for node in rpm.",
  "environment_sensor_min_temperature": "Minimum temperature of all non-ambient sensors for node in Celsius.",
  "environment_sensor_power": "Power consumed by a node in Watts.",
  "environment_sensor_status": "This metric indicates a value of 1 if the sensor threshold state is normal (indicating the sensor is operating within normal parameters) and a value of 0 for any other state.",
  "environment_sensor_threshold_value": "Provides the sensor reading.",
  "ethernet_switch_port_receive_discards": "Total number of discarded packets.",
  "ethernet_switch_port_receive_errors": "Number of packet errors.",
  "ethernet_switch_port_receive_packets": "Total packet count.",
  "ethernet_switch_port_transmit_discards": "Total number of discarded packets.",
  "ethernet_switch_port_transmit_errors": "Number of packet errors.",
  "ethernet_switch_port_transmit_packets": "Total packet count.",
  "export_rule_labels": "This metric provides information about ExportRule",
  "external_service_op_num_not_found_responses": "Number of \u0026apos;Not Found\u0026apos; responses for calls to this operation.",
  "external_service_op_num_request_failures": "A cumulative count of all request failures.",
  "external_service_op_num_requests_sent": "Number of requests sent to this service.",
  "external_service_op_num_responses_received": "Number of responses received from the server (does not include timeouts).",
  "external_service_op_num_successful_responses": "Number of successful responses to this operation.",
  "external_service_op_num_timeouts": "Number of times requests to the server for this operation timed out, meaning no response was recevied in a given time period.",
  "external_service_op_request_latency": "Average latency of requests for operations of this type on this server.",
  "external_service_op_request_latency_hist": "This histogram holds the latency values for requests of this operation to the specified server.",
  "fabricpool_average_latency": "This counter is deprecated.Average latencies executed during various phases of command execution. The execution-start latency represents the average time taken to start executing an operation. The request-prepare latency represent the average time taken to prepare the commplete request that needs to be sent to the server. The send latency represents the average time taken to send requests to the server. The execution-start-to-send-complete represents the average time taken to send an operation out since its execution started. The execution-start-to-first-byte-received represent the average time taken to receive the first byte of a response since the command's request execution started. These counters can be used to identify performance bottlenecks within the object store client module.",
  "fabricpool_cloud_bin_op_latency_average": "Cloud bin operation latency average in milliseconds.",
  "fabricpool_cloud_bin_operation": "Cloud bin operation counters.",
  "fabricpool_get_throughput_bytes": "This counter is deprecated. Counter that indicates the throughput for GET command in bytes per second.",
  "fabricpool_put_throughput_bytes": "This counter is deprecated. Counter that indicates the throughput for PUT command in bytes per second.",
  "fabricpool_stats": "This counter is deprecated. Counter that indicates the number of object store operations sent, and their success and failure counts. The objstore_client_op_name array indicate the operation name such as PUT, GET, etc. The objstore_client_op_stats_name array contain the total number of operations, their success and failure counter for each operation.",
  "fabricpool_throughput_ops": "Counter that indicates the throughput for commands in ops per second.",
  "fcp_avg_other_latency": "Average latency for operations other than read and write",
  "fcp_avg_read_latency": "Average latency for read operations",
  "fcp_avg_write_latency": "Average latency for write operations",
  "fcp_discarded_frames_count": "Number of discarded frames.",
  "fcp_fabric_connected_speed": "The negotiated data rate between the target FC port and the fabric in gigabits per second.",
  "fcp_int_count": "Number of interrupts",
  "fcp_invalid_crc": "Number of invalid cyclic redundancy checks (CRC count)",
  "fcp_invalid_transmission_word": "Number of invalid transmission words",
  "fcp_isr_count": "Number of interrupt responses",
  "fcp_labels": "This metric provides information about FCP",
  "fcp_lif_avg_latency": "Average latency for FCP operations",
  "fcp_lif_avg_other_latency": "Average latency for operations other than read and write",
  "fcp_lif_avg_read_latency": "Average latency for read operations",
  "fcp_lif_avg_write_latency": "Average latency for write operations",
  "fcp_lif_other_ops": "Number of operations that are not read or write.",
  "fcp_lif_read_data": "Amount of data read from the storage system",
  "fcp_lif_read_ops": "Number of read operations",
  "fcp_lif_total_ops": "Total number of operations.",
  "fcp_lif_write_data": "Amount of data written to the storage system",
  "fcp_lif_write_ops": "Number of write operations",
  "fcp_link_down": "Number of times the Fibre Channel link was lost",
  "fcp_link_failure": "Number of link failures",
  "fcp_link_up": "Number of times the Fibre Channel link was established",
  "fcp_loss_of_signal": "Number of times this port lost signal",
  "fcp_loss_of_sync": "Number of times this port lost sync",
  "fcp_max_speed": "The maximum speed supported by the FC port in gigabits per second.",
  "fcp_nvmf_avg_other_latency": "Average latency for operations other than read and write (FC-NVMe)",
  "fcp_nvmf_avg_read_latency": "Average latency for read operations (FC-NVMe)",
  "fcp_nvmf_avg_remote_other_latency": "Average latency for remote operations other than read and write (FC-NVMe)",
  "fcp_nvmf_avg_remote_read_latency": "Average latency for remote read operations (FC-NVMe)",
  "fcp_nvmf_avg_remote_write_latency": "Average latency for remote write operations (FC-NVMe)",
  "fcp_nvmf_avg_write_latency": "Average latency for write operations (FC-NVMe)",
  "fcp_nvmf_caw_data": "Amount of CAW data sent to the storage system (FC-NVMe)",
  "fcp_nvmf_caw_ops": "Number of FC-NVMe CAW operations",
  "fcp_nvmf_command_slots": "Number of command slots that have been used by initiators logging into this port. This shows the command fan-in on the port.",
  "fcp_nvmf_other_ops": "Number of NVMF operations that are not read or write.",
  "fcp_nvmf_read_data": "Amount of data read from the storage system (FC-NVMe)",
  "fcp_nvmf_read_ops": "Number of FC-NVMe read operations",
  "fcp_nvmf_remote_caw_data": "Amount of remote CAW data sent to the storage system (FC-NVMe)",
  "fcp_nvmf_remote_caw_ops": "Number of FC-NVMe remote CAW operations",
  "fcp_nvmf_remote_other_ops": "Number of NVMF remote operations that are not read or write.",
  "fcp_nvmf_remote_read_data": "Amount of remote data read from the storage system (FC-NVMe)",
  "fcp_nvmf_remote_read_ops": "Number of FC-NVMe remote read operations",
  "fcp_nvmf_remote_total_data": "Amount of remote FC-NVMe traffic to and from the storage system",
  "fcp_nvmf_remote_total_ops": "Total number of remote FC-NVMe operations",
  "fcp_nvmf_remote_write_data": "Amount of remote data written to the storage system (FC-NVMe)",
  "fcp_nvmf_remote_write_ops": "Number of FC-NVMe remote write operations",
  "fcp_nvmf_total_data": "Amount of FC-NVMe traffic to and from the storage system",
  "fcp_nvmf_total_ops": "Total number of FC-NVMe operations",
  "fcp_nvmf_write_data": "Amount of data written to the storage system (FC-NVMe)",
  "fcp_nvmf_write_ops": "Number of FC-NVMe write operations",
  "fcp_other_ops": "Number of operations that are not read or write.",
  "fcp_prim_seq_err": "Number of primitive sequence errors",
  "fcp_queue_full": "Number of times a queue full condition occurred.",
  "fcp_read_data": "Amount of data read from the storage system",
  "fcp_read_ops": "Number of read operations",
  "fcp_reset_count": "Number of physical port resets",
  "fcp_shared_int_count": "Number of shared interrupts",
  "fcp_spurious_int_count": "Number of spurious interrupts",
  "fcp_threshold_full": "Number of times the total number of outstanding commands on the port exceeds the threshold supported by this port.",
  "fcp_total_data": "Amount of FCP traffic to and from the storage system",
  "fcp_total_ops": "Total number of FCP operations",
  "fcp_write_data": "Amount of data written to the storage system",
  "fcp_write_ops": "Number of write operations",
  "fcvi_firmware_invalid_crc_count": "Firmware reported invalid CRC count",
  "fcvi_firmware_invalid_transmit_word_count": "Firmware reported invalid transmit word count",
  "fcvi_firmware_link_failure_count": "Firmware reported link failure count",
  "fcvi_firmware_loss_of_signal_count": "Firmware reported loss of signal count",
  "fcvi_firmware_loss_of_sync_count": "Firmware reported loss of sync count",
  "fcvi_firmware_systat_discard_frames": "Firmware reported SyStatDiscardFrames value",
  "fcvi_hard_reset_count": "Number of times hard reset of FCVI adapter got issued.",
  "fcvi_rdma_write_avg_latency": "Average RDMA write I/O latency.",
  "fcvi_rdma_write_ops": "Number of RDMA write I/Os issued per second.",
  "fcvi_rdma_write_throughput": "RDMA write throughput in bytes per second.",
  "fcvi_soft_reset_count": "Number of times soft reset of FCVI adapter got issued.",
  "flashcache_accesses": "External cache accesses per second",
  "flashcache_disk_reads_replaced": "Estimated number of disk reads per second replaced by cache",
  "flashcache_evicts": "Number of blocks evicted from the external cache to make room for new blocks",
  "flashcache_hit": "Number of WAFL buffers served off the external cache",
  "flashcache_hit_directory": "Number of directory buffers served off the external cache",
  "flashcache_hit_indirect": "Number of indirect file buffers served off the external cache",
  "flashcache_hit_metadata_file": "Number of metadata file buffers served off the external cache",
  "flashcache_hit_normal_lev0": "Number of normal level 0 WAFL buffers served off the external cache",
  "flashcache_hit_percent": "External cache hit rate",
  "flashcache_inserts": "Number of WAFL buffers inserted into the external cache",
  "flashcache_invalidates": "Number of blocks invalidated in the external cache",
  "flashcache_miss": "External cache misses",
  "flashcache_miss_directory": "External cache misses accessing directory buffers",
  "flashcache_miss_indirect": "External cache misses accessing indirect file buffers",
  "flashcache_miss_metadata_file": "External cache misses accessing metadata file buffers",
  "flashcache_miss_normal_lev0": "External cache misses accessing normal level 0 buffers",
  "flashcache_usage": "Percentage of blocks in external cache currently containing valid data",
  "flashpool_cache_stats": "Automated Working-set Analyzer (AWA) per-interval pseudo cache statistics for the most recent intervals. The number of intervals defined as recent is CM_WAFL_HYAS_INT_DIS_CNT. This array is a table with fields corresponding to the enum type of hyas_cache_stat_type_t.",
  "flashpool_evict_destage_rate": "Number of block destage per second.",
  "flashpool_evict_remove_rate": "Number of block free per second.",
  "flashpool_hya_read_hit_latency_average": "Average of RAID I/O latency on read hit.",
  "flashpool_hya_read_miss_latency_average": "Average read miss latency.",
  "flashpool_hya_write_hdd_latency_average": "Average write latency to HDD.",
  "flashpool_hya_write_ssd_latency_average": "Average of RAID I/O latency on write to SSD.",
  "flashpool_read_cache_ins_rate": "Cache insert rate blocks/sec.",
  "flashpool_read_ops_replaced": "Number of HDD read operations replaced by SSD reads per second.",
  "flashpool_read_ops_replaced_percent": "Percentage of HDD read operations replace by SSD.",
  "flashpool_ssd_available": "Total SSD blocks available.",
  "flashpool_ssd_read_cached": "Total read cached SSD blocks.",
  "flashpool_ssd_total": "Total SSD blocks.",
  "flashpool_ssd_total_used": "Total SSD blocks used.",
  "flashpool_ssd_write_cached": "Total write cached SSD blocks.",
  "flashpool_wc_write_blks_total": "Number of write-cache blocks written per second.",
  "flashpool_write_blks_replaced": "Number of HDD write blocks replaced by SSD writes per second.",
  "flashpool_write_blks_replaced_percent": "Percentage of blocks overwritten to write-cache among all disk writes.",
  "flexcache_blocks_requested_from_client": "Total blocks requested by the client.",
  "flexcache_blocks_retrieved_from_origin": "Blocks retrieved from origin in case of a cache miss. This can be divided by the raw client_requested_blocks and multiplied by 100 to calculate the cache miss percentage.",
  "flexcache_evict_rw_cache_skipped_reason_disconnected": "Total number of read-write cache evict operations skipped because cache is disconnected.",
  "flexcache_evict_skipped_reason_config_noent": "Total number of evict operation is skipped because cache config is not available.",
  "flexcache_evict_skipped_reason_disconnected": "Total number of evict operation is skipped because cache is disconnected.",
  "flexcache_evict_skipped_reason_offline": "Total number of evict operation is skipped because cache volume is offline.",
  "flexcache_invalidate_skipped_reason_config_noent": "Total number of invalidate operation is skipped because cache config is not available.",
  "flexcache_invalidate_skipped_reason_disconnected": "Total number of invalidate operation is skipped because cache is disconnected.",
  "flexcache_invalidate_skipped_reason_offline": "Total number of invalidate operation is skipped because cache volume is offline.",
  "flexcache_miss_percent": "This metric represents the percentage of block requests from a client that resulted in a \"miss\" in the FlexCache. A \"miss\" occurs when the requested data is not found in the cache and has to be retrieved from the origin volume.",
  "flexcache_nix_retry_skipped_reason_initiator_retrieve": "Total retry nix operations skipped because the initiator is retrieve operation.",
  "flexcache_nix_skipped_reason_config_noent": "Total number of nix operation is skipped because cache config is not available.",
  "flexcache_nix_skipped_reason_disconnected": "Total number of nix operation is skipped because cache is disconnected.",
  "flexcache_nix_skipped_reason_in_progress": "Total nix operations skipped because of an in-progress nix.",
  "flexcache_nix_skipped_reason_offline": "Total number of nix operation is skipped because cache volume is offline.",
  "flexcache_reconciled_data_entries": "Total number of reconciled data entries at cache side.",
  "flexcache_reconciled_lock_entries": "Total number of reconciled lock entries at cache side.",
  "flexcache_size": "Physical size of the volume, in bytes. The minimum size for a FlexVol volume is 20MB and the minimum size for a FlexGroup volume is 200MB per constituent. The recommended size for a FlexGroup volume is a minimum of 100GB per constituent. For all volumes, the default size is equal to the minimum size.",
  "fpolicy_aborted_requests": "Number of screen requests aborted",
  "fpolicy_denied_requests": "Number of screen requests for which deny is received from fpolicy server",
  "fpolicy_io_processing_latency": "Average IO processing latency for screen request",
  "fpolicy_io_thread_wait_latency": "Average IO thread wait latency for the screen request",
  "fpolicy_processed_requests": "Number of screen requests went through fpolicy processing",
  "fpolicy_processing_latency": "Average policy processing latency for screen request",
  "fpolicy_server_cancelled_requests": "Number of screen requests whose processing was cancelled (cancel timeout)",
  "fpolicy_server_failed_requests": "Number of screen requests the node failed to send to fpolicy server",
  "fpolicy_server_max_request_latency": "Maximum latency for a screen request",
  "fpolicy_server_outstanding_requests": "Total number of screen requests waiting for response",
  "fpolicy_server_processed_requests": "Total number of screen requests processed(sync and async)",
  "fpolicy_server_request_latency": "Average latency for screen request",
  "fpolicy_svm_aborted_requests": "Number of screen requests aborted",
  "fpolicy_svm_cifs_requests": "Number of cifs screen requests sent to fpolicy server",
  "fpolicy_svm_failedop_notifications": "Number of failed file operation notifications sent to fpolicy server",
  "fpolicy_svm_io_processing_latency": "Average IO processing latency for screen request",
  "fpolicy_svm_io_thread_wait_latency": "Average IO thread wait latency for screen request",
  "fru_status": "This metric indicates a value of 1 if the FRU status is ok and a value of 0 for any other state.",
  "headroom_aggr_current_latency": "This is the storage aggregate average latency per message at the disk level.",
  "headroom_aggr_current_ops": "Total number of I/Os processed by the aggregate per second.",
  "headroom_aggr_current_utilization": "This is the storage aggregate average utilization of all the data disks in the aggregate.",
  "headroom_aggr_ewma_daily": "Daily exponential weighted moving average.",
  "headroom_aggr_ewma_hourly": "Hourly exponential weighted moving average.",
  "headroom_aggr_ewma_monthly": "Monthly exponential weighted moving average.",
  "headroom_aggr_ewma_weekly": "Weekly exponential weighted moving average.",
  "headroom_aggr_optimal_point_confidence_factor": "The confidence factor for the optimal point value based on the observed resource latency and utilization.",
  "headroom_aggr_optimal_point_latency": "The latency component of the optimal point of the latency/utilization curve.",
  "headroom_aggr_optimal_point_ops": "The ops component of the optimal point derived from the latency/utilzation curve.",
  "headroom_aggr_optimal_point_utilization": "The utilization component of the optimal point of the latency/utilization curve.",
  "headroom_cpu_current_latency": "Current operation latency of the resource.",
  "headroom_cpu_current_ops": "Total number of operations per second (also referred to as dblade ops).",
  "headroom_cpu_current_utilization": "Average processor utilization across all processors in the system.",
  "headroom_cpu_ewma_daily": "Daily exponential weighted moving average for current_ops, optimal_point_ops, current_latency, optimal_point_latency, current_utilization, optimal_point_utilization and optimal_point_confidence_factor.",
  "headroom_cpu_ewma_hourly": "Hourly exponential weighted moving average for current_ops, optimal_point_ops, current_latency, optimal_point_latency, current_utilization, optimal_point_utilization and optimal_point_confidence_factor.",
  "headroom_cpu_ewma_monthly": "Monthly exponential weighted moving average for current_ops, optimal_point_ops, current_latency, optimal_point_latency, current_utilization, optimal_point_utilization and optimal_point_confidence_factor.",
  "headroom_cpu_ewma_weekly": "Weekly exponential weighted moving average for current_ops, optimal_point_ops, current_latency, optimal_point_latency, current_utilization, optimal_point_utilization and optimal_point_confidence_factor.",
  "headroom_cpu_optimal_point_confidence_factor": "Confidence factor for the optimal point value based on the observed resource latency and utilization. The possible values are: 0 - unknown, 1 - low, 2 - medium, 3 - high. This counter can provide an average confidence factor over a range of time.",
  "headroom_cpu_optimal_point_latency": "Latency component of the optimal point of the latency/utilization curve. This counter can provide an average latency over a range of time.",
  "headroom_cpu_optimal_point_ops": "Ops component of the optimal point derived from the latency/utilization curve. This counter can provide an average ops over a range of time.",
  "headroom_cpu_optimal_point_utilization": "Utilization component of the optimal point of the latency/utilization curve. This counter can provide an average utilization over a range of time.",
  "health_disk_alerts": "Provides any issues related to Disks health check if disks are broken or unassigned. Value of 1 means issue is happening and 0 means that issue is resolved.",
  "health_ems_alerts": "The health_ems_alerts metric monitors EMS (Event Management System), providing a count based on their severity and other attributes. This metric includes labels such as node, message, source, and severity (e.g., emergency, alert, error). By default, it monitors alerts with emergency severity.",
  "health_ha_alerts": "Provides any issues related to HA health check. Value of 1 means issue is happening and 0 means that issue is resolved.",
  "health_license_alerts": "Provides any issues related to License health check. Value of 1 means issue is happening and 0 means that issue is resolved.",
  "health_lif_alerts": "Provides any issues related to LIF health check. Value of 1 means issue is happening and 0 means that issue is resolved.",
  "health_network_ethernet_port_alerts": "Provides any issues related to Network Ethernet Port health check. Value of 1 means issue is happening and 0 means that issue is resolved.",
  "health_network_fc_port_alerts": "Provides any issues related to Network FC Port health check. Value of 1 means issue is happening and 0 means that issue is resolved.",
  "health_node_alerts": "Provides any issues related to Node health check. Value of 1 means issue is happening and 0 means that issue is resolved.",
  "health_shelf_alerts": "Provides any issues related to Shelf health check. Value of 1 means issue is happening and 0 means that issue is resolved.",
  "health_support_alerts": "Provides any issues related to Support health check. Value of 1 means issue is happening and 0 means that issue is resolved.",
  "health_volume_move_alerts": "Provides any issues related to Volume Move health check. Value of 1 means issue is happening and 0 means that issue is resolved.",
  "health_volume_ransomware_alerts": "Provides any issues related to Volume Ransomware health check. Value of 1 means issue is happening and 0 means that issue is resolved.",
  "hostadapter_bytes_read": "Bytes read through a host adapter",
  "hostadapter_bytes_written": "Bytes written through a host adapter",
  "igroup_labels": "Details of Igroups in the cluster.",
  "iscsi_lif_avg_latency": "Average latency for iSCSI operations",
  "iscsi_lif_avg_other_latency": "Average latency for operations other than read and write (for example, Inquiry, Report LUNs, SCSI Task Management Functions)",
  "iscsi_lif_avg_read_latency": "Average latency for read operations",
  "iscsi_lif_avg_write_latency": "Average latency for write operations",
  "iscsi_lif_cmd_transfered": "Command transferred by this iSCSI connection",
  "iscsi_lif_iscsi_other_ops": "iSCSI other operations per second on this logical interface (LIF)",
  "iscsi_lif_iscsi_read_ops": "iSCSI read operations per second on this logical interface (LIF)",
  "iscsi_lif_iscsi_write_ops": "iSCSI write operations per second on this logical interface (LIF)",
  "iscsi_lif_protocol_errors": "Number of protocol errors from iSCSI sessions on this logical interface (LIF)",
  "iscsi_lif_read_data": "Amount of data read from the storage system in bytes",
  "iscsi_lif_write_data": "Amount of data written to the storage system in bytes",
  "iw_avg_latency": "Average RDMA I/O latency.",
  "iw_ops": "Number of RDMA I/Os issued.",
  "iw_read_ops": "Number of RDMA read I/Os issued.",
  "iw_write_ops": "Number of RDMA write I/Os issued.",
  "lif_labels": "This metric provides information about LIF",
  "lif_recv_data": "Number of bytes received per second",
  "lif_recv_errors": "Number of received Errors per second",
  "lif_recv_packet": "Number of packets received per second",
  "lif_sent_data": "Number of bytes sent per second",
  "lif_sent_errors": "Number of sent errors per second",
  "lif_sent_packet": "Number of packets sent per second",
  "lif_total_data": "Performance metric aggregated over all types of I/O operations.",
  "lif_uptime": "Interface up time",
  "lun_avg_read_latency": "Average read latency in microseconds for all operations on the LUN",
  "lun_avg_write_latency": "Average write latency in microseconds for all operations on the LUN",
  "lun_avg_xcopy_latency": "Average latency in microseconds for xcopy requests",
  "lun_block_size": "Represent the block size being used",
  "lun_caw_reqs": "Number of compare and write requests",
  "lun_enospc": "Number of operations receiving ENOSPC errors",
  "lun_labels": "This metric provides information about Lun",
  "lun_new_status": "This metric indicates a value of 1 if the LUN state is online (indicating the LUN is operational) and a value of 0 for any other state. and a value of 0 for any other state.",
  "lun_other_data": "Performance metric for other I/O operations. Other I/O operations can be metadata operations, such as directory lookups and so on.",
  "lun_other_latency": "Performance metric for other I/O operations. Other I/O operations can be metadata operations, such as directory lookups and so on.",
  "lun_other_ops": "Performance metric for other I/O operations. Other I/O operations can be metadata operations, such as directory lookups and so on.",
  "lun_queue_full": "Queue full responses",
  "lun_read_align_histo": "Histogram of WAFL read alignment (number sectors off WAFL block start)",
  "lun_read_data": "Read bytes",
  "lun_read_ops": "Number of read operations",
  "lun_read_partial_blocks": "Percentage of reads whose size is not a multiple of WAFL block size",
  "lun_remote_bytes": "I/O to or from a LUN which is not owned by the storage system handling the I/O.",
  "lun_remote_ops": "Number of operations received by a storage system that does not own the LUN targeted by the operations.",
  "lun_size": "The total provisioned size of the LUN. The LUN size can be increased but not decreased using the REST interface.\u003cbr/\u003eThe maximum and minimum sizes listed here are the absolute maximum and absolute minimum sizes, in bytes. The actual minimum and maximum sizes vary depending on the ONTAP version, ONTAP platform and the available space in the containing volume and aggregate.\u003cbr/\u003eFor more information, see _Size properties_ in the _docs_ section of the ONTAP REST API documentation.",
  "lun_size_used": "The amount of space consumed by the main data stream of the LUN.\u003cbr/\u003eThis value is the total space consumed in the volume by the LUN, including filesystem overhead, but excluding prefix and suffix streams. Due to internal filesystem overhead and the many ways SAN filesystems and applications utilize blocks within a LUN, this value does not necessarily reflect actual consumption/availability from the perspective of the filesystem or application. Without specific knowledge of how the LUN blocks are utilized outside of ONTAP, this property should not be used as an indicator for an out-of-space condition.\u003cbr/\u003eFor more information, see _Size properties_ in the _docs_ section of the ONTAP REST API documentation.",
  "lun_size_used_percent": "This metric represents the percentage of a LUN that is currently being used.",
  "lun_total_data": "Total of Read and write bytes",
  "lun_total_latency": "Performance metric aggregated over all types of I/O operations.",
  "lun_total_ops": "Total number of read and write operations",
  "lun_unmap_reqs": "Number of unmap command requests",
  "lun_write_align_histo": "Histogram of WAFL write alignment (number of sectors off WAFL block start)",
  "lun_write_data": "Write bytes",
  "lun_write_ops": "Number of write operations",
  "lun_write_partial_blocks": "Percentage of writes whose size is not a multiple of WAFL block size",
  "lun_writesame_reqs": "Number of write same command requests",
  "lun_writesame_unmap_reqs": "Number of write same commands requests with unmap bit set",
  "lun_xcopy_reqs": "Total number of xcopy operations on the LUN",
  "mav_request_approve_expiry_time": "Shows the deadline by which approved operations must be approved.",
  "mav_request_approve_time": "Shows the date and time when requests were approved.",
  "mav_request_create_time": "Displays the date and time each MAV request was initiated.",
  "mav_request_details": "This metric provides information about MAV requests.",
  "mav_request_execution_expiry_time": "Shows the deadline by which approved operations must be executed.",
  "mediator_labels": "This metric provides information about Mediator",
  "metadata_collector_api_time": "amount of time to collect data from monitored cluster object",
  "metadata_collector_bytesRx": "The amount of data received by the collector from the monitored cluster.",
  "metadata_collector_calc_time": "amount of time it took to compute metrics between two successive polls, specifically using properties like raw, delta, rate, average, and percent. This metric is available for ZapiPerf/RestPerf collectors.",
  "metadata_collector_instances": "number of objects collected from monitored cluster",
  "metadata_collector_metrics": "number of counters collected from monitored cluster",
  "metadata_collector_numCalls": "The number of API calls made by the collector to the monitored cluster.",
  "metadata_collector_numPartials": "The number of partial responses received by the collector from the monitored cluster.",
  "metadata_collector_parse_time": "amount of time to parse XML, JSON, etc. for cluster object",
  "metadata_collector_pluginInstances": "The number of plugin instances generated by the collector.",
  "metadata_collector_plugin_time": "amount of time for all plugins to post-process metrics",
  "metadata_collector_poll_time": "amount of time it took for the poll to finish",
  "metadata_collector_skips": "number of metrics that were not calculated between two successive polls. This metric is available for ZapiPerf/RestPerf collectors.",
  "metadata_collector_task_time": "amount of time it took for each collector's subtasks to complete",
  "metadata_component_count": "number of metrics collected for each object",
  "metadata_component_status": "status of the collector - 0 means running, 1 means standby, 2 means failed",
  "metadata_exporter_count": "number of metrics and labels exported",
  "metadata_exporter_time": "amount of time it took to render, export, and serve exported data",
  "metadata_target_goroutines": "number of goroutines that exist within the poller",
  "metadata_target_ping": "The response time (in milliseconds) of the ping to the target system. If the ping is successful, the metric records the time it took for the ping to complete.",
  "metadata_target_status": "status of the system being monitored. 0 means reachable, 1 means unreachable",
  "metrocluster_check_aggr_status": "Detail of the type of diagnostic operation run for the Aggregate with diagnostic operation result.",
  "metrocluster_check_cluster_status": "Detail of the type of diagnostic operation run for the Cluster with diagnostic operation result.",
  "metrocluster_check_node_status": "Detail of the type of diagnostic operation run for the Node with diagnostic operation result.",
  "metrocluster_check_volume_status": "Detail of the type of diagnostic operation run for the Volume with diagnostic operation result.",
  "namespace_avg_other_latency": "Average other ops latency in microseconds for all operations on the Namespace",
  "namespace_avg_read_latency": "Average read latency in microseconds for all operations on the Namespace",
  "namespace_avg_total_latency": "Performance metric aggregated over all types of I/O operations.",
  "namespace_avg_write_latency": "Average write latency in microseconds for all operations on the Namespace",
  "namespace_block_size": "The size of blocks in the namespace in bytes. The default for namespaces with an `os_type` of _vmware_ is _512_. All other namespaces default to _4096_.\u003cbr/\u003eValid in POST when creating an NVMe namespace that is not a clone of another. Disallowed in POST when creating a namespace clone. Valid in POST.",
  "namespace_labels": "This metric provides information about Namespace",
  "namespace_other_ops": "Number of other operations",
  "namespace_read_data": "Read bytes",
  "namespace_read_ops": "Number of read operations",
  "namespace_remote_other_ops": "Number of remote other operations",
  "namespace_remote_read_data": "Remote read bytes",
  "namespace_remote_read_ops": "Number of remote read operations",
  "namespace_remote_write_data": "Remote write bytes",
  "namespace_remote_write_ops": "Number of remote write operations",
  "namespace_size": "The total provisioned size of the NVMe namespace. Valid in POST and PATCH. The NVMe namespace size can be increased but not be made smaller using the REST interface.\u003cbr/\u003eThe maximum and minimum sizes listed here are the absolute maximum and absolute minimum sizes in bytes. The maximum size is variable with respect to large NVMe namespace support in ONTAP. If large namespaces are supported, the maximum size is 128 TB (140737488355328 bytes) and if not supported, the maximum size is just under 16 TB (17557557870592 bytes). The minimum size supported is always 4096 bytes.\u003cbr/\u003eFor more information, see _Size properties_ in the _docs_ section of the ONTAP REST API documentation.",
  "namespace_size_available": "This metric represents the amount of available space in a namespace.",
  "namespace_size_available_percent": "This metric represents the percentage of available space in a namespace.",
  "namespace_size_used": "The amount of space consumed by the main data stream of the NVMe namespace.\u003cbr/\u003eThis value is the total space consumed in the volume by the NVMe namespace, including filesystem overhead, but excluding prefix and suffix streams. Due to internal filesystem overhead and the many ways NVMe filesystems and applications utilize blocks within a namespace, this value does not necessarily reflect actual consumption/availability from the perspective of the filesystem or application. Without specific knowledge of how the namespace blocks are utilized outside of ONTAP, this property should not be used and an indicator for an out-of-space condition.\u003cbr/\u003eFor more information, see _Size properties_ in the _docs_ section of the ONTAP REST API documentation.",
  "namespace_total_data": "Performance metric aggregated over all types of I/O operations.",
  "namespace_total_ops": "Performance metric aggregated over all types of I/O operations.",
  "namespace_write_data": "Write bytes",
  "namespace_write_ops": "Number of write operations",
  "ndmp_session_data_bytes_processed": "Indicates the NDMP data bytes processed.",
  "ndmp_session_mover_bytes_moved": "Indicates the NDMP mover bytes moved.",
  "net_connection_labels": "This metric provides information about NetConnections",
  "net_port_mtu": "Maximum transmission unit, largest packet size on this network",
  "net_port_status": "This metric indicates a value of 1 if the port state is up and a value of 0 for any other state.",
  "net_route_labels": "This metric provides information about NetRoute",
  "netstat_bytes_recvd": "Number of bytes received by a TCP connection",
  "netstat_bytes_sent": "Number of bytes sent by a TCP connection",
  "netstat_cong_win": "Congestion window of a TCP connection",
  "netstat_cong_win_th": "Congestion window threshold of a TCP connection",
  "netstat_ooorcv_pkts": "Number of out-of-order packets received by this TCP connection",
  "netstat_recv_window": "Receive window size of a TCP connection",
  "netstat_rexmit_pkts": "Number of packets retransmitted by this TCP connection",
  "netstat_send_window": "Send window size of a TCP connection",
  "nfs_clients_idle_duration": "Specifies an ISO-8601 format of date and time to retrieve the idle time duration in hours, minutes, and seconds format.",
  "nfs_diag_storePool_ByteLockAlloc": "Current number of byte range lock objects allocated.",
  "nfs_diag_storePool_ByteLockMax": "Maximum number of byte range lock objects.",
  "nfs_diag_storePool_ClientAlloc": "Current number of client objects allocated.",
  "nfs_diag_storePool_ClientMax": "Maximum number of client objects.",
  "nfs_diag_storePool_ConnectionParentSessionReferenceAlloc": "Current number of connection parent session reference objects allocated.",
  "nfs_diag_storePool_ConnectionParentSessionReferenceMax": "Maximum number of connection parent session reference objects.",
  "nfs_diag_storePool_CopyStateAlloc": "Current number of copy state objects allocated.",
  "nfs_diag_storePool_CopyStateMax": "Maximum number of copy state objects.",
  "nfs_diag_storePool_DelegAlloc": "Current number of delegation lock objects allocated.",
  "nfs_diag_storePool_DelegMax": "Maximum number delegation lock objects.",
  "nfs_diag_storePool_DelegStateAlloc": "Current number of delegation state objects allocated.",
  "nfs_diag_storePool_DelegStateMax": "Maximum number of delegation state objects.",
  "nfs_diag_storePool_LayoutAlloc": "Current number of layout objects allocated.",
  "nfs_diag_storePool_LayoutMax": "Maximum number of layout objects.",
  "nfs_diag_storePool_LayoutStateAlloc": "Current number of layout state objects allocated.",
  "nfs_diag_storePool_LayoutStateMax": "Maximum number of layout state objects.",
  "nfs_diag_storePool_LockStateAlloc": "Current number of lock state objects allocated.",
  "nfs_diag_storePool_LockStateMax": "Maximum number of lock state objects.",
  "nfs_diag_storePool_OpenAlloc": "Current number of share objects allocated.",
  "nfs_diag_storePool_OpenMax": "Maximum number of share lock objects.",
  "nfs_diag_storePool_OpenStateAlloc": "Current number of open state objects allocated.",
  "nfs_diag_storePool_OpenStateMax": "Maximum number of open state objects.",
  "nfs_diag_storePool_OwnerAlloc": "Current number of owner objects allocated.",
  "nfs_diag_storePool_OwnerMax": "Maximum number of owner objects.",
  "nfs_diag_storePool_SessionAlloc": "Current number of session objects allocated.",
  "nfs_diag_storePool_SessionConnectionHolderAlloc": "Current number of session connection holder objects allocated.",
  "nfs_diag_storePool_SessionConnectionHolderMax": "Maximum number of session connection holder objects.",
  "nfs_diag_storePool_SessionHolderAlloc": "Current number of session holder objects allocated.",
  "nfs_diag_storePool_SessionHolderMax": "Maximum number of session holder objects.",
  "nfs_diag_storePool_SessionMax": "Maximum number of session objects.",
  "nfs_diag_storePool_StateRefHistoryAlloc": "Current number of state reference callstack history objects allocated.",
  "nfs_diag_storePool_StateRefHistoryMax": "Maximum number of state reference callstack history objects.",
  "nfs_diag_storePool_StringAlloc": "Current number of string objects allocated.",
  "nfs_diag_storePool_StringMax": "Maximum number of string objects.",
  "nic_ifgrp_rx_bytes": "Link Aggregation Group (LAG) Bytes received.",
  "nic_ifgrp_tx_bytes": "Link Aggregation Group (LAG) Bytes sent.",
  "nic_labels": "This metric provides information about NicCommon",
  "nic_link_up_to_downs": "Number of link state change from UP to DOWN.",
  "nic_new_status": "This metric indicates a value of 1 if the NIC state is up (indicating the NIC is operational) and a value of 0 for any other state.",
  "nic_rx_alignment_errors": "Alignment errors detected on received packets",
  "nic_rx_bytes": "Bytes received",
  "nic_rx_crc_errors": "CRC errors detected on received packets",
  "nic_rx_errors": "Error received",
  "nic_rx_length_errors": "Length errors detected on received packets",
  "nic_rx_percent": "Bytes received percentage.",
  "nic_rx_total_errors": "Total errors received",
  "nic_tx_bytes": "Bytes sent",
  "nic_tx_errors": "Error sent",
  "nic_tx_hw_errors": "Transmit errors reported by hardware",
  "nic_tx_percent": "Bytes sent percentage.",
  "nic_tx_total_errors": "Total errors sent",
  "nic_util_percent": "Max of Bytes received percentage and Bytes sent percentage.",
  "node_avg_processor_busy": "Average processor utilization across active processors in the system",
  "node_cifs_connections": "Number of connections",
  "node_cifs_established_sessions": "Number of established SMB and SMB2 sessions",
  "node_cifs_latency": "Average latency for CIFS operations",
  "node_cifs_op_count": "Array of select CIFS operation counts",
  "node_cifs_open_files": "Number of open files over SMB and SMB2",
  "node_cifs_ops": "Number of CIFS operations per second",
  "node_cifs_read_latency": "Average latency for CIFS read operations",
  "node_cifs_read_ops": "Total number of CIFS read operations",
  "node_cifs_total_ops": "Total number of CIFS operations",
  "node_cifs_write_latency": "Average latency for CIFS write operations",
  "node_cifs_write_ops": "Total number of CIFS write operations",
  "node_cpu_busy": "System CPU resource utilization. Returns a computed percentage for the default CPU field. Basically computes a 'cpu usage summary' value which indicates how 'busy' the system is based upon the most heavily utilized domain. The idea is to determine the amount of available CPU until we're limited by either a domain maxing out OR we exhaust all available idle CPU cycles, whichever occurs first.",
  "node_cpu_busytime": "The time (in hundredths of a second) that the CPU has been doing useful work since the last boot",
  "node_cpu_domain_busy": "Array of processor time in percentage spent in various domains",
  "node_cpu_elapsed_time": "Elapsed time since boot",
  "node_disk_busy": "The utilization percent of the disk. node_disk_busy is [disk_busy](#disk_busy) aggregated by `node`.",
  "node_disk_capacity": "Disk capacity in MB. node_disk_capacity is [disk_capacity](#disk_capacity) aggregated by `node`.",
  "node_disk_cp_read_chain": "Average number of blocks transferred in each consistency point read operation during a CP. node_disk_cp_read_chain is [disk_cp_read_chain](#disk_cp_read_chain) aggregated by `node`.",
  "node_disk_cp_read_latency": "Average latency per block in microseconds for consistency point read operations. node_disk_cp_read_latency is [disk_cp_read_latency](#disk_cp_read_latency) aggregated by `node`.",
  "node_disk_cp_reads": "Number of disk read operations initiated each second for consistency point processing. node_disk_cp_reads is [disk_cp_reads](#disk_cp_reads) aggregated by `node`.",
  "node_disk_data_read": "Number of disk kilobytes (KB) read per second",
  "node_disk_data_written": "Number of disk kilobytes (KB) written per second",
  "node_disk_io_pending": "Average number of I/Os issued to the disk for which we have not yet received the response. node_disk_io_pending is [disk_io_pending](#disk_io_pending) aggregated by `node`.",
  "node_disk_io_queued": "Number of I/Os queued to the disk but not yet issued. node_disk_io_queued is [disk_io_queued](#disk_io_queued) aggregated by `node`.",
  "node_disk_max_busy": "The utilization percent of the disk. node_disk_max_busy is the maximum of [disk_busy](#disk_busy) for label `node`.",
  "node_disk_max_capacity": "Disk capacity in MB. node_disk_max_capacity is the maximum of [disk_capacity](#disk_capacity) for label `node`.",
  "node_disk_max_cp_read_chain": "Average number of blocks transferred in each consistency point read operation during a CP. node_disk_max_cp_read_chain is the maximum of [disk_cp_read_chain](#disk_cp_read_chain) for label `node`.",
  "node_disk_max_cp_read_latency": "Average latency per block in microseconds for consistency point read operations. node_disk_max_cp_read_latency is the maximum of [disk_cp_read_latency](#disk_cp_read_latency) for label `node`.",
  "node_disk_max_cp_reads": "Number of disk read operations initiated each second for consistency point processing. node_disk_max_cp_reads is the maximum of [disk_cp_reads](#disk_cp_reads) for label `node`.",
  "node_disk_max_io_pending": "Average number of I/Os issued to the disk for which we have not yet received the response. node_disk_max_io_pending is the maximum of [disk_io_pending](#disk_io_pending) for label `node`.",
  "node_disk_max_io_queued": "Number of I/Os queued to the disk but not yet issued. node_disk_max_io_queued is the maximum of [disk_io_queued](#disk_io_queued) for label `node`.",
  "node_disk_max_total_data": "Total throughput for user operations per second. node_disk_max_total_data is the maximum of [disk_total_data](#disk_total_data) for label `node`.",
  "node_disk_max_total_transfers": "Total number of disk operations involving data transfer initiated per second. node_disk_max_total_transfers is the maximum of [disk_total_transfers](#disk_total_transfers) for label `node`.",
  "node_disk_max_user_read_blocks": "Number of blocks transferred for user read operations per second. node_disk_max_user_read_blocks is the maximum of [disk_user_read_blocks](#disk_user_read_blocks) for label `node`.",
  "node_disk_max_user_read_chain": "Average number of blocks transferred in each user read operation. node_disk_max_user_read_chain is the maximum of [disk_user_read_chain](#disk_user_read_chain) for label `node`.",
  "node_disk_max_user_read_latency": "Average latency per block in microseconds for user read operations. node_disk_max_user_read_latency is the maximum of [disk_user_read_latency](#disk_user_read_latency) for label `node`.",
  "node_disk_max_user_reads": "Number of disk read operations initiated each second for retrieving data or metadata associated with user requests. node_disk_max_user_reads is the maximum of [disk_user_reads](#disk_user_reads) for label `node`.",
  "node_disk_max_user_write_blocks": "Number of blocks transferred for user write operations per second. node_disk_max_user_write_blocks is the maximum of [disk_user_write_blocks](#disk_user_write_blocks) for label `node`.",
  "node_disk_max_user_write_chain": "Average number of blocks transferred in each user write operation. node_disk_max_user_write_chain is the maximum of [disk_user_write_chain](#disk_user_write_chain) for label `node`.",
  "node_disk_max_user_write_latency": "Average latency per block in microseconds for user write operations. node_disk_max_user_write_latency is the maximum of [disk_user_write_latency](#disk_user_write_latency) for label `node`.",
  "node_disk_max_user_writes": "Number of disk write operations initiated each second for storing data or metadata associated with user requests. node_disk_max_user_writes is the maximum of [disk_user_writes](#disk_user_writes) for label `node`.",
  "node_disk_total_data": "Total throughput for user operations per second. node_disk_total_data is [disk_total_data](#disk_total_data) aggregated by `node`.",
  "node_disk_total_transfers": "Total number of disk operations involving data transfer initiated per second. node_disk_total_transfers is [disk_total_transfers](#disk_total_transfers) aggregated by `node`.",
  "node_disk_user_read_blocks": "Number of blocks transferred for user read operations per second. node_disk_user_read_blocks is [disk_user_read_blocks](#disk_user_read_blocks) aggregated by `node`.",
  "node_disk_user_read_chain": "Average number of blocks transferred in each user read operation. node_disk_user_read_chain is [disk_user_read_chain](#disk_user_read_chain) aggregated by `node`.",
  "node_disk_user_read_latency": "Average latency per block in microseconds for user read operations. node_disk_user_read_latency is [disk_user_read_latency](#disk_user_read_latency) aggregated by `node`.",
  "node_disk_user_reads": "Number of disk read operations initiated each second for retrieving data or metadata associated with user requests. node_disk_user_reads is [disk_user_reads](#disk_user_reads) aggregated by `node`.",
  "node_disk_user_write_blocks": "Number of blocks transferred for user write operations per second. node_disk_user_write_blocks is [disk_user_write_blocks](#disk_user_write_blocks) aggregated by `node`.",
  "node_disk_user_write_chain": "Average number of blocks transferred in each user write operation. node_disk_user_write_chain is [disk_user_write_chain](#disk_user_write_chain) aggregated by `node`.",
  "node_disk_user_write_latency": "Average latency per block in microseconds for user write operations. node_disk_user_write_latency is [disk_user_write_latency](#disk_user_write_latency) aggregated by `node`.",
  "node_disk_user_writes": "Number of disk write operations initiated each second for storing data or metadata associated with user requests. node_disk_user_writes is [disk_user_writes](#disk_user_writes) aggregated by `node`.",
  "node_failed_fan": "Specifies a count of the number of chassis fans that are not operating within the recommended RPM range.",
  "node_failed_power": "Number of failed power supply units.",
  "node_fcp_data_recv": "Number of FCP kilobytes (KB) received per second",
  "node_fcp_data_sent": "Number of FCP kilobytes (KB) sent per second",
  "node_fcp_ops": "Number of FCP operations per second",
  "node_hdd_data_read": "Number of HDD Disk kilobytes (KB) read per second",
  "node_hdd_data_written": "Number of HDD kilobytes (KB) written per second",
  "node_iscsi_ops": "Number of iSCSI operations per second",
  "node_labels": "This metric provides information about Node",
  "node_memory": "Total memory in megabytes (MB)",
  "node_net_data_recv": "Number of network kilobytes (KB) received per second",
  "node_net_data_sent": "Number of network kilobytes (KB) sent per second",
  "node_new_status": "This metric indicates a value of 1 if the node is healthy (true or up, indicating the node is operational) and a value of 0 for any other state.",
  "node_nfs_access_avg_latency": "Average latency of Access procedure requests. The counter keeps track of the average response time of Access requests.",
  "node_nfs_access_total": "Total number of Access procedure requests. It is the total number of access success and access error requests.",
  "node_nfs_backchannel_ctl_avg_latency": "Average latency of BACKCHANNEL_CTL operations.",
  "node_nfs_backchannel_ctl_total": "Total number of BACKCHANNEL_CTL operations.",
  "node_nfs_bind_conn_to_session_avg_latency": "Average latency of BIND_CONN_TO_SESSION operations.",
  "node_nfs_bind_conn_to_session_total": "Total number of BIND_CONN_TO_SESSION operations.",
  "node_nfs_close_avg_latency": "Average latency of CLOSE operations.",
  "node_nfs_close_total": "Total number of CLOSE operations.",
  "node_nfs_commit_avg_latency": "Average latency of Commit procedure requests. The counter keeps track of the average response time of Commit requests.",
  "node_nfs_commit_total": "Total number of Commit procedure requests. It is the total number of Commit success and Commit error requests.",
  "node_nfs_create_avg_latency": "Average latency of Create procedure requests. The counter keeps track of the average response time of Create requests.",
  "node_nfs_create_session_avg_latency": "Average latency of CREATE_SESSION operations.",
  "node_nfs_create_session_total": "Total number of CREATE_SESSION operations.",
  "node_nfs_create_total": "Total number Create of procedure requests. It is the total number of create success and create error requests.",
  "node_nfs_delegpurge_avg_latency": "Average latency of DELEGPURGE operations.",
  "node_nfs_delegpurge_total": "Total number of DELEGPURGE operations.",
  "node_nfs_delegreturn_avg_latency": "Average latency of DELEGRETURN operations.",
  "node_nfs_delegreturn_total": "Total number of DELEGRETURN operations.",
  "node_nfs_destroy_clientid_avg_latency": "Average latency of DESTROY_CLIENTID operations.",
  "node_nfs_destroy_clientid_total": "Total number of DESTROY_CLIENTID operations.",
  "node_nfs_destroy_session_avg_latency": "Average latency of DESTROY_SESSION operations.",
  "node_nfs_destroy_session_total": "Total number of DESTROY_SESSION operations.",
  "node_nfs_exchange_id_avg_latency": "Average latency of EXCHANGE_ID operations.",
  "node_nfs_exchange_id_total": "Total number of EXCHANGE_ID operations.",
  "node_nfs_free_stateid_avg_latency": "Average latency of FREE_STATEID operations.",
  "node_nfs_free_stateid_total": "Total number of FREE_STATEID operations.",
  "node_nfs_fsinfo_avg_latency": "Average latency of FSInfo procedure requests. The counter keeps track of the average response time of FSInfo requests.",
  "node_nfs_fsinfo_total": "Total number FSInfo of procedure requests. It is the total number of FSInfo success and FSInfo error requests.",
  "node_nfs_fsstat_avg_latency": "Average latency of FSStat procedure requests. The counter keeps track of the average response time of FSStat requests.",
  "node_nfs_fsstat_total": "Total number FSStat of procedure requests. It is the total number of FSStat success and FSStat error requests.",
  "node_nfs_get_dir_delegation_avg_latency": "Average latency of GET_DIR_DELEGATION operations.",
  "node_nfs_get_dir_delegation_total": "Total number of GET_DIR_DELEGATION operations.",
  "node_nfs_getattr_avg_latency": "Average latency of GetAttr procedure requests. This counter keeps track of the average response time of GetAttr requests.",
  "node_nfs_getattr_total": "Total number of Getattr procedure requests. It is the total number of getattr success and getattr error requests.",
  "node_nfs_getdeviceinfo_avg_latency": "Average latency of GETDEVICEINFO operations.",
  "node_nfs_getdeviceinfo_total": "Total number of GETDEVICEINFO operations.",
  "node_nfs_getdevicelist_avg_latency": "Average latency of GETDEVICELIST operations.",
  "node_nfs_getdevicelist_total": "Total number of GETDEVICELIST operations.",
  "node_nfs_getfh_avg_latency": "Average latency of GETFH operations.",
  "node_nfs_getfh_total": "Total number of GETFH operations.",
  "node_nfs_latency": "Average latency of NFSv3 requests. This counter keeps track of the average response time of NFSv3 requests.",
  "node_nfs_layoutcommit_avg_latency": "Average latency of LAYOUTCOMMIT operations.",
  "node_nfs_layoutcommit_total": "Total number of LAYOUTCOMMIT operations.",
  "node_nfs_layoutget_avg_latency": "Average latency of LAYOUTGET operations.",
  "node_nfs_layoutget_total": "Total number of LAYOUTGET operations.",
  "node_nfs_layoutreturn_avg_latency": "Average latency of LAYOUTRETURN operations.",
  "node_nfs_layoutreturn_total": "Total number of LAYOUTRETURN operations.",
  "node_nfs_link_avg_latency": "Average latency of Link procedure requests. The counter keeps track of the average response time of Link requests.",
  "node_nfs_link_total": "Total number Link of procedure requests. It is the total number of Link success and Link error requests.",
  "node_nfs_lock_avg_latency": "Average latency of LOCK operations.",
  "node_nfs_lock_total": "Total number of LOCK operations.",
  "node_nfs_lockt_avg_latency": "Average latency of LOCKT operations.",
  "node_nfs_lockt_total": "Total number of LOCKT operations.",
  "node_nfs_locku_avg_latency": "Average latency of LOCKU operations.",
  "node_nfs_locku_total": "Total number of LOCKU operations.",
  "node_nfs_lookup_avg_latency": "Average latency of LookUp procedure requests. This shows the average time it takes for the LookUp operation to reply to the request.",
  "node_nfs_lookup_total": "Total number of Lookup procedure requests. It is the total number of lookup success and lookup error requests.",
  "node_nfs_lookupp_avg_latency": "Average latency of LOOKUPP operations.",
  "node_nfs_lookupp_total": "Total number of LOOKUPP operations.",
  "node_nfs_mkdir_avg_latency": "Average latency of MkDir procedure requests. The counter keeps track of the average response time of MkDir requests.",
  "node_nfs_mkdir_total": "Total number MkDir of procedure requests. It is the total number of MkDir success and MkDir error requests.",
  "node_nfs_mknod_avg_latency": "Average latency of MkNod procedure requests. The counter keeps track of the average response time of MkNod requests.",
  "node_nfs_mknod_total": "Total number MkNod of procedure requests. It is the total number of MkNod success and MkNod error requests.",
  "node_nfs_null_avg_latency": "Average latency of Null procedure requests.",
  "node_nfs_null_total": "Total number of Null procedure requests. It is the total of null success and null error requests.",
  "node_nfs_nverify_avg_latency": "Average latency of NVERIFY operations.",
  "node_nfs_nverify_total": "Total number of NVERIFY operations.",
  "node_nfs_open_avg_latency": "Average latency of OPEN operations.",
  "node_nfs_open_confirm_avg_latency": "Average latency of OPEN_CONFIRM procedures",
  "node_nfs_open_confirm_total": "Total number of OPEN_CONFIRM procedures",
  "node_nfs_open_downgrade_avg_latency": "Average latency of OPEN_DOWNGRADE operations.",
  "node_nfs_open_downgrade_total": "Total number of OPEN_DOWNGRADE operations.",
  "node_nfs_open_total": "Total number of OPEN operations.",
  "node_nfs_openattr_avg_latency": "Average latency of OPENATTR operations.",
  "node_nfs_openattr_total": "Total number of OPENATTR operations.",
  "node_nfs_ops": "Number of NFS operations per second",
  "node_nfs_pathconf_avg_latency": "Average latency of PathConf procedure requests. The counter keeps track of the average response time of PathConf requests.",
  "node_nfs_pathconf_total": "Total number PathConf of procedure requests. It is the total number of PathConf success and PathConf error requests.",
  "node_nfs_putfh_avg_latency": "The number of successful PUTPUBFH operations.",
  "node_nfs_putfh_total": "Total number of PUTFH operations.",
  "node_nfs_putpubfh_avg_latency": "Average latency of PUTPUBFH operations.",
  "node_nfs_putpubfh_total": "Total number of PUTPUBFH operations.",
  "node_nfs_putrootfh_avg_latency": "Average latency of PUTROOTFH operations.",
  "node_nfs_putrootfh_total": "Total number of PUTROOTFH operations.",
  "node_nfs_read_avg_latency": "Average latency of Read procedure requests. The counter keeps track of the average response time of Read requests.",
  "node_nfs_read_ops": "Total observed NFSv3 read operations per second.",
  "node_nfs_read_symlink_avg_latency": "Average latency of ReadSymLink procedure requests. The counter keeps track of the average response time of ReadSymLink requests.",
  "node_nfs_read_symlink_total": "Total number of ReadSymLink procedure requests. It is the total number of read symlink success and read symlink error requests.",
  "node_nfs_read_throughput": "Rate of NFSv3 read data transfers per second.",
  "node_nfs_read_total": "Total number Read of procedure requests. It is the total number of read success and read error requests.",
  "node_nfs_readdir_avg_latency": "Average latency of ReadDir procedure requests. The counter keeps track of the average response time of ReadDir requests.",
  "node_nfs_readdir_total": "Total number ReadDir of procedure requests. It is the total number of ReadDir success and ReadDir error requests.",
  "node_nfs_readdirplus_avg_latency": "Average latency of ReadDirPlus procedure requests. The counter keeps track of the average response time of ReadDirPlus requests.",
  "node_nfs_readdirplus_total": "Total number ReadDirPlus of procedure requests. It is the total number of ReadDirPlus success and ReadDirPlus error requests.",
  "node_nfs_readlink_avg_latency": "Average latency of READLINK operations.",
  "node_nfs_readlink_total": "Total number of READLINK operations.",
  "node_nfs_reclaim_complete_avg_latency": "Average latency of RECLAIM_COMPLETE operations.",
  "node_nfs_reclaim_complete_total": "Total number of RECLAIM_COMPLETE operations.",
  "node_nfs_release_lock_owner_avg_latency": "Average Latency of RELEASE_LOCKOWNER procedures",
  "node_nfs_release_lock_owner_total": "Total number of RELEASE_LOCKOWNER procedures",
  "node_nfs_remove_avg_latency": "Average latency of Remove procedure requests. The counter keeps track of the average response time of Remove requests.",
  "node_nfs_remove_total": "Total number Remove of procedure requests. It is the total number of Remove success and Remove error requests.",
  "node_nfs_rename_avg_latency": "Average latency of Rename procedure requests. The counter keeps track of the average response time of Rename requests.",
  "node_nfs_rename_total": "Total number Rename of procedure requests. It is the total number of Rename success and Rename error requests.",
  "node_nfs_renew_avg_latency": "Average latency of RENEW procedures",
  "node_nfs_renew_total": "Total number of RENEW procedures",
  "node_nfs_restorefh_avg_latency": "Average latency of RESTOREFH operations.",
  "node_nfs_restorefh_total": "Total number of RESTOREFH operations.",
  "node_nfs_rmdir_avg_latency": "Average latency of RmDir procedure requests. The counter keeps track of the average response time of RmDir requests.",
  "node_nfs_rmdir_total": "Total number RmDir of procedure requests. It is the total number of RmDir success and RmDir error requests.",
  "node_nfs_savefh_avg_latency": "Average latency of SAVEFH operations.",
  "node_nfs_savefh_total": "Total number of SAVEFH operations.",
  "node_nfs_secinfo_avg_latency": "Average latency of SECINFO operations.",
  "node_nfs_secinfo_no_name_avg_latency": "Average latency of SECINFO_NO_NAME operations.",
  "node_nfs_secinfo_no_name_total": "Total number of SECINFO_NO_NAME operations.",
  "node_nfs_secinfo_total": "Total number of SECINFO operations.",
  "node_nfs_sequence_avg_latency": "Average latency of SEQUENCE operations.",
  "node_nfs_sequence_total": "Total number of SEQUENCE operations.",
  "node_nfs_set_ssv_avg_latency": "Average latency of SET_SSV operations.",
  "node_nfs_set_ssv_total": "Total number of SET_SSV operations.",
  "node_nfs_setattr_avg_latency": "Average latency of SetAttr procedure requests. The counter keeps track of the average response time of SetAttr requests.",
  "node_nfs_setattr_total": "Total number of Setattr procedure requests. It is the total number of Setattr success and setattr error requests.",
  "node_nfs_setclientid_avg_latency": "Average latency of SETCLIENTID procedures",
  "node_nfs_setclientid_confirm_avg_latency": "Average latency of SETCLIENTID_CONFIRM procedures",
  "node_nfs_setclientid_confirm_total": "Total number of SETCLIENTID_CONFIRM procedures",
  "node_nfs_setclientid_total": "Total number of SETCLIENTID procedures",
  "node_nfs_symlink_avg_latency": "Average latency of SymLink procedure requests. The counter keeps track of the average response time of SymLink requests.",
  "node_nfs_symlink_total": "Total number SymLink of procedure requests. It is the total number of SymLink success and create SymLink requests.",
  "node_nfs_test_stateid_avg_latency": "Average latency of TEST_STATEID operations.",
  "node_nfs_test_stateid_total": "Total number of TEST_STATEID operations.",
  "node_nfs_throughput": "Rate of NFSv3 data transfers per second.",
  "node_nfs_total_ops": "Total number of NFSv3 procedure requests per second.",
  "node_nfs_verify_avg_latency": "Average latency of VERIFY operations.",
  "node_nfs_verify_total": "Total number of VERIFY operations.",
  "node_nfs_want_delegation_avg_latency": "Average latency of WANT_DELEGATION operations.",
  "node_nfs_want_delegation_total": "Total number of WANT_DELEGATION operations.",
  "node_nfs_write_avg_latency": "Average latency of Write procedure requests. The counter keeps track of the average response time of Write requests.",
  "node_nfs_write_ops": "Total observed NFSv3 write operations per second.",
  "node_nfs_write_throughput": "Rate of NFSv3 write data transfers per second.",
  "node_nfs_write_total": "Total number of Write procedure requests. It is the total number of write success and write error requests.",
  "node_nvme_fc_data_recv": "NVMe/FC kilobytes (KB) received per second",
  "node_nvme_fc_data_sent": "NVMe/FC kilobytes (KB) sent per second",
  "node_nvme_fc_ops": "NVMe/FC operations per second",
  "node_nvmf_data_recv": "NVMe/FC kilobytes (KB) received per second.",
  "node_nvmf_data_sent": "NVMe/FC kilobytes (KB) sent per second.",
  "node_nvmf_ops": "NVMe/FC operations per second.",
  "node_other_data": "Other throughput",
  "node_other_latency": "Average latency for all other operations in the system in microseconds",
  "node_other_ops": "All other operations per second",
  "node_read_data": "Read throughput",
  "node_read_latency": "Average latency for all read operations in the system in microseconds",
  "node_read_ops": "Read operations per second",
  "node_ssd_data_read": "Number of SSD Disk kilobytes (KB) read per second",
  "node_ssd_data_written": "Number of SSD Disk kilobytes (KB) written per second",
  "node_total_data": "Represents the total data throughput in bytes for a node, as reported by ONTAP.",
  "node_total_latency": "Average latency for all operations in the system in microseconds",
  "node_total_ops": "Total number of operations per second",
  "node_uptime": "The total time, in seconds, that the node has been up.",
  "node_volume_avg_latency": "Performance metric aggregated over all types of I/O operations. node_volume_avg_latency is [volume_avg_latency](#volume_avg_latency) aggregated by `node`.",
  "node_volume_nfs_access_latency": "The raw data component latency in microseconds measured within ONTAP for all operations of the given type. node_volume_nfs_access_latency is [volume_nfs_access_latency](#volume_nfs_access_latency) aggregated by `node`.",
  "node_volume_nfs_access_ops": "Number of operations of the given type performed on this volume. node_volume_nfs_access_ops is [volume_nfs_access_ops](#volume_nfs_access_ops) aggregated by `node`.",
  "node_volume_nfs_getattr_latency": "The raw data component latency in microseconds measured within ONTAP for all operations of the given type. node_volume_nfs_getattr_latency is [volume_nfs_getattr_latency](#volume_nfs_getattr_latency) aggregated by `node`.",
  "node_volume_nfs_getattr_ops": "Number of operations of the given type performed on this volume. node_volume_nfs_getattr_ops is [volume_nfs_getattr_ops](#volume_nfs_getattr_ops) aggregated by `node`.",
  "node_volume_nfs_lookup_latency": "The raw data component latency in microseconds measured within ONTAP for all operations of the given type. node_volume_nfs_lookup_latency is [volume_nfs_lookup_latency](#volume_nfs_lookup_latency) aggregated by `node`.",
  "node_volume_nfs_lookup_ops": "Number of operations of the given type performed on this volume. node_volume_nfs_lookup_ops is [volume_nfs_lookup_ops](#volume_nfs_lookup_ops) aggregated by `node`.",
  "node_volume_nfs_other_latency": "Average time for the WAFL filesystem to process other NFS operations to the volume; not including NFS protocol request processing or network communication time which will also be included in client observed NFS request latency (Note: This is applicable only for ONTAP 9.9 and below. Harvest uses KeyPerf collector for ONTAP 9.10 onwards.). node_volume_nfs_other_latency is [volume_nfs_other_latency](#volume_nfs_other_latency) aggregated by `node`.",
  "node_volume_nfs_other_ops": "Number of other NFS operations per second to the volume (Note: This is applicable only for ONTAP 9.9 and below. Harvest uses KeyPerf collector for ONTAP 9.10 onwards.). node_volume_nfs_other_ops is [volume_nfs_other_ops](#volume_nfs_other_ops) aggregated by `node`.",
  "node_volume_nfs_punch_hole_latency": "Average time for the WAFL filesystem to process NFS protocol hole-punch requests to the volume (Note: This is applicable only for ONTAP 9.9 and below. Harvest uses KeyPerf collector for ONTAP 9.10 onwards.). node_volume_nfs_punch_hole_latency is [volume_nfs_punch_hole_latency](#volume_nfs_punch_hole_latency) aggregated by `node`.",
  "node_volume_nfs_punch_hole_ops": "Number of NFS hole-punch requests per second to the volume (Note: This is applicable only for ONTAP 9.9 and below. Harvest uses KeyPerf collector for ONTAP 9.10 onwards.). node_volume_nfs_punch_hole_ops is [volume_nfs_punch_hole_ops](#volume_nfs_punch_hole_ops) aggregated by `node`.",
  "node_volume_nfs_read_latency": "The raw data component latency in microseconds measured within ONTAP for all operations of the given type. node_volume_nfs_read_latency is [volume_nfs_read_latency](#volume_nfs_read_latency) aggregated by `node`.",
  "node_volume_nfs_read_ops": "Number of operations of the given type performed on this volume. node_volume_nfs_read_ops is [volume_nfs_read_ops](#volume_nfs_read_ops) aggregated by `node`.",
  "node_volume_nfs_setattr_latency": "The raw data component latency in microseconds measured within ONTAP for all operations of the given type. node_volume_nfs_setattr_latency is [volume_nfs_setattr_latency](#volume_nfs_setattr_latency) aggregated by `node`.",
  "node_volume_nfs_setattr_ops": "Number of operations of the given type performed on this volume. node_volume_nfs_setattr_ops is [volume_nfs_setattr_ops](#volume_nfs_setattr_ops) aggregated by `node`.",
  "node_volume_nfs_total_ops": "Number of total NFS operations per second to the volume (Note: This is applicable only for ONTAP 9.9 and below. Harvest uses KeyPerf collector for ONTAP 9.10 onwards.). node_volume_nfs_total_ops is [volume_nfs_total_ops](#volume_nfs_total_ops) aggregated by `node`.",
  "node_volume_nfs_write_latency": "The raw data component latency in microseconds measured within ONTAP for all operations of the given type. node_volume_nfs_write_latency is [volume_nfs_write_latency](#volume_nfs_write_latency) aggregated by `node`.",
  "node_volume_nfs_write_ops": "Number of operations of the given type performed on this volume. node_volume_nfs_write_ops is [volume_nfs_write_ops](#volume_nfs_write_ops) aggregated by `node`.",
  "node_volume_other_data": "Performance metric for other I/O operations. Other I/O operations can be metadata operations, such as directory lookups and so on. node_volume_other_data is [volume_other_data](#volume_other_data) aggregated by `node`.",
  "node_volume_other_latency": "Performance metric for other I/O operations. Other I/O operations can be metadata operations, such as directory lookups and so on. node_volume_other_latency is [volume_other_latency](#volume_other_latency) aggregated by `node`.",
  "node_volume_other_ops": "Performance metric for other I/O operations. Other I/O operations can be metadata operations, such as directory lookups and so on. node_volume_other_ops is [volume_other_ops](#volume_other_ops) aggregated by `node`.",
  "node_volume_read_data": "Performance metric for read I/O operations. node_volume_read_data is [volume_read_data](#volume_read_data) aggregated by `node`.",
  "node_volume_read_latency": "Performance metric for read I/O operations. node_volume_read_latency is [volume_read_latency](#volume_read_latency) aggregated by `node`.",
  "node_volume_read_ops": "Performance metric for read I/O operations. node_volume_read_ops is [volume_read_ops](#volume_read_ops) aggregated by `node`.",
  "node_volume_total_data": "Represents the aggregated total data throughput in bytes across all volumes on a node. This metric is calculated by Harvest by summing the data read from and written to each volume on the node.",
  "node_volume_total_ops": "Performance metric aggregated over all types of I/O operations. node_volume_total_ops is [volume_total_ops](#volume_total_ops) aggregated by `node`.",
  "node_volume_write_data": "Performance metric for write I/O operations. node_volume_write_data is [volume_write_data](#volume_write_data) aggregated by `node`.",
  "node_volume_write_latency": "Performance metric for write I/O operations. node_volume_write_latency is [volume_write_latency](#volume_write_latency) aggregated by `node`.",
  "node_volume_write_ops": "Performance metric for write I/O operations. node_volume_write_ops is [volume_write_ops](#volume_write_ops) aggregated by `node`.",
  "node_write_data": "Write throughput",
  "node_write_latency": "Average latency for all write operations in the system in microseconds",
  "node_write_ops": "Write operations per second",
  "ntpserver_labels": "This metric provides information about NtpServer",
  "nvm_mirror_write_throughput": "Mirror throughput in Bytes per second",
  "nvme_lif_avg_latency": "Average latency for NVMF operations",
  "nvme_lif_avg_other_latency": "Average latency for operations other than read, write, compare or compare-and-write.",
  "nvme_lif_avg_read_latency": "Average latency for read operations",
  "nvme_lif_avg_write_latency": "Average latency for write operations",
  "nvme_lif_other_ops": "Number of operations that are not read, write, compare or compare-and-write.",
  "nvme_lif_read_data": "Amount of data read from the storage system",
  "nvme_lif_read_ops": "Number of read operations",
  "nvme_lif_total_ops": "Total number of operations.",
  "nvme_lif_write_data": "Amount of data written to the storage system",
  "nvme_lif_write_ops": "Number of write operations",
  "nvmf_rdma_port_avg_latency": "Average latency for NVMF operations",
  "nvmf_rdma_port_avg_other_latency": "Average latency for operations other than read, write, compare or compare-and-write",
  "nvmf_rdma_port_avg_read_latency": "Average latency for read operations",
  "nvmf_rdma_port_avg_write_latency": "Average latency for write operations",
  "nvmf_rdma_port_other_ops": "Number of operations that are not read, write, compare or compare-and-right.",
  "nvmf_rdma_port_read_data": "Amount of data read from the storage system",
  "nvmf_rdma_port_read_ops": "Number of read operations",
  "nvmf_rdma_port_total_data": "Amount of NVMF traffic to and from the storage system",
  "nvmf_rdma_port_total_ops": "Total number of operations.",
  "nvmf_rdma_port_write_data": "Amount of data written to the storage system",
  "nvmf_rdma_port_write_ops": "Number of write operations",
  "nvmf_tcp_port_avg_latency": "Average latency for NVMF operations",
  "nvmf_tcp_port_avg_other_latency": "Average latency for operations other than read, write, compare or compare-and-write",
  "nvmf_tcp_port_avg_read_latency": "Average latency for read operations",
  "nvmf_tcp_port_avg_write_latency": "Average latency for write operations",
  "nvmf_tcp_port_other_ops": "Number of operations that are not read, write, compare or compare-and-write.",
  "nvmf_tcp_port_read_data": "Amount of data read from the storage system",
  "nvmf_tcp_port_read_ops": "Number of read operations",
  "nvmf_tcp_port_total_data": "Amount of NVMF traffic to and from the storage system",
  "nvmf_tcp_port_total_ops": "Total number of operations.",
  "nvmf_tcp_port_write_data": "Amount of data written to the storage system",
  "nvmf_tcp_port_write_ops": "Number of write operations",
  "ontaps3_labels": "This metric provides information about OntapS3",
  "ontaps3_logical_used_size": "Specifies the bucket logical used size up to this point. This field cannot be specified using a POST or PATCH method.",
  "ontaps3_policy_labels": "This metric provides information about OntapS3Policy",
  "ontaps3_size": "Specifies the bucket size in bytes; ranges from 190MB to 62PB.",
  "ontaps3_svm_abort_multipart_upload_failed": "Number of failed Abort Multipart Upload operations. ontaps3_svm_abort_multipart_upload_failed is [ontaps3_svm_abort_multipart_upload_failed](#ontaps3_svm_abort_multipart_upload_failed) aggregated by `svm`.",
  "ontaps3_svm_abort_multipart_upload_failed_client_close": "Number of times Abort Multipart Upload operation failed because client terminated connection while the operation was still pending on server. ontaps3_svm_abort_multipart_upload_failed_client_close is [ontaps3_svm_abort_multipart_upload_failed_client_close](#ontaps3_svm_abort_multipart_upload_failed_client_close) aggregated by `svm`.",
  "ontaps3_svm_abort_multipart_upload_latency": "Average latency for Abort Multipart Upload operations. ontaps3_svm_abort_multipart_upload_latency is [ontaps3_svm_abort_multipart_upload_latency](#ontaps3_svm_abort_multipart_upload_latency) aggregated by `svm`.",
  "ontaps3_svm_abort_multipart_upload_rate": "Number of Abort Multipart Upload operations per second. ontaps3_svm_abort_multipart_upload_rate is [ontaps3_svm_abort_multipart_upload_rate](#ontaps3_svm_abort_multipart_upload_rate) aggregated by `svm`.",
  "ontaps3_svm_abort_multipart_upload_total": "Number of Abort Multipart Upload operations. ontaps3_svm_abort_multipart_upload_total is [ontaps3_svm_abort_multipart_upload_total](#ontaps3_svm_abort_multipart_upload_total) aggregated by `svm`.",
  "ontaps3_svm_allow_access": "Number of times access was allowed. ontaps3_svm_allow_access is [ontaps3_svm_allow_access](#ontaps3_svm_allow_access) aggregated by `svm`.",
  "ontaps3_svm_anonymous_access": "Number of times anonymous access was allowed. ontaps3_svm_anonymous_access is [ontaps3_svm_anonymous_access](#ontaps3_svm_anonymous_access) aggregated by `svm`.",
  "ontaps3_svm_anonymous_deny_access": "Number of times anonymous access was denied. ontaps3_svm_anonymous_deny_access is [ontaps3_svm_anonymous_deny_access](#ontaps3_svm_anonymous_deny_access) aggregated by `svm`.",
  "ontaps3_svm_authentication_failures": "Number of authentication failures. ontaps3_svm_authentication_failures is [ontaps3_svm_authentication_failures](#ontaps3_svm_authentication_failures) aggregated by `svm`.",
  "ontaps3_svm_chunked_upload_reqs": "Total number of object store server chunked object upload requests. ontaps3_svm_chunked_upload_reqs is [ontaps3_svm_chunked_upload_reqs](#ontaps3_svm_chunked_upload_reqs) aggregated by `svm`.",
  "ontaps3_svm_complete_multipart_upload_failed": "Number of failed Complete Multipart Upload operations. ontaps3_svm_complete_multipart_upload_failed is [ontaps3_svm_complete_multipart_upload_failed](#ontaps3_svm_complete_multipart_upload_failed) aggregated by `svm`.",
  "ontaps3_svm_complete_multipart_upload_failed_client_close": "Number of times Complete Multipart Upload operation failed because client terminated connection while the operation was still pending on server. ontaps3_svm_complete_multipart_upload_failed_client_close is [ontaps3_svm_complete_multipart_upload_failed_client_close](#ontaps3_svm_complete_multipart_upload_failed_client_close) aggregated by `svm`.",
  "ontaps3_svm_complete_multipart_upload_latency": "Average latency for Complete Multipart Upload operations. ontaps3_svm_complete_multipart_upload_latency is [ontaps3_svm_complete_multipart_upload_latency](#ontaps3_svm_complete_multipart_upload_latency) aggregated by `svm`.",
  "ontaps3_svm_complete_multipart_upload_rate": "Number of Complete Multipart Upload operations per second. ontaps3_svm_complete_multipart_upload_rate is [ontaps3_svm_complete_multipart_upload_rate](#ontaps3_svm_complete_multipart_upload_rate) aggregated by `svm`.",
  "ontaps3_svm_complete_multipart_upload_total": "Number of Complete Multipart Upload operations. ontaps3_svm_complete_multipart_upload_total is [ontaps3_svm_complete_multipart_upload_total](#ontaps3_svm_complete_multipart_upload_total) aggregated by `svm`.",
  "ontaps3_svm_connected_connections": "Number of object store server connections currently established. ontaps3_svm_connected_connections is [ontaps3_svm_connected_connections](#ontaps3_svm_connected_connections) aggregated by `svm`.",
  "ontaps3_svm_connections": "Total number of object store server connections. ontaps3_svm_connections is [ontaps3_svm_connections](#ontaps3_svm_connections) aggregated by `svm`.",
  "ontaps3_svm_create_bucket_failed": "Number of failed Create Bucket operations. ontaps3_svm_create_bucket_failed is [ontaps3_svm_create_bucket_failed](#ontaps3_svm_create_bucket_failed) aggregated by `svm`.",
  "ontaps3_svm_create_bucket_failed_client_close": "Number of times Create Bucket operation failed because client terminated connection while the operation was still pending on server. ontaps3_svm_create_bucket_failed_client_close is [ontaps3_svm_create_bucket_failed_client_close](#ontaps3_svm_create_bucket_failed_client_close) aggregated by `svm`.",
  "ontaps3_svm_create_bucket_latency": "Average latency for Create Bucket operations. ontaps3_svm_create_bucket_latency is [ontaps3_svm_create_bucket_latency](#ontaps3_svm_create_bucket_latency) aggregated by `svm`.",
  "ontaps3_svm_create_bucket_rate": "Number of Create Bucket operations per second. ontaps3_svm_create_bucket_rate is [ontaps3_svm_create_bucket_rate](#ontaps3_svm_create_bucket_rate) aggregated by `svm`.",
  "ontaps3_svm_create_bucket_total": "Number of Create Bucket operations. ontaps3_svm_create_bucket_total is [ontaps3_svm_create_bucket_total](#ontaps3_svm_create_bucket_total) aggregated by `svm`.",
  "ontaps3_svm_default_deny_access": "Number of times access was denied by default and not through any policy statement. ontaps3_svm_default_deny_access is [ontaps3_svm_default_deny_access](#ontaps3_svm_default_deny_access) aggregated by `svm`.",
  "ontaps3_svm_delete_bucket_failed": "Number of failed Delete Bucket operations. ontaps3_svm_delete_bucket_failed is [ontaps3_svm_delete_bucket_failed](#ontaps3_svm_delete_bucket_failed) aggregated by `svm`.",
  "ontaps3_svm_delete_bucket_failed_client_close": "Number of times Delete Bucket operation failed because client terminated connection while the operation was still pending on server. ontaps3_svm_delete_bucket_failed_client_close is [ontaps3_svm_delete_bucket_failed_client_close](#ontaps3_svm_delete_bucket_failed_client_close) aggregated by `svm`.",
  "ontaps3_svm_delete_bucket_latency": "Average latency for Delete Bucket operations. ontaps3_svm_delete_bucket_latency is [ontaps3_svm_delete_bucket_latency](#ontaps3_svm_delete_bucket_latency) aggregated by `svm`.",
  "ontaps3_svm_delete_bucket_rate": "Number of Delete Bucket operations per second. ontaps3_svm_delete_bucket_rate is [ontaps3_svm_delete_bucket_rate](#ontaps3_svm_delete_bucket_rate) aggregated by `svm`.",
  "ontaps3_svm_delete_bucket_total": "Number of Delete Bucket operations. ontaps3_svm_delete_bucket_total is [ontaps3_svm_delete_bucket_total](#ontaps3_svm_delete_bucket_total) aggregated by `svm`.",
  "ontaps3_svm_delete_object_failed": "Number of failed DELETE object operations. ontaps3_svm_delete_object_failed is [ontaps3_svm_delete_object_failed](#ontaps3_svm_delete_object_failed) aggregated by `svm`.",
  "ontaps3_svm_delete_object_failed_client_close": "Number of times DELETE object operation failed due to the case where client closed the connection while the operation was still pending on server. ontaps3_svm_delete_object_failed_client_close is [ontaps3_svm_delete_object_failed_client_close](#ontaps3_svm_delete_object_failed_client_close) aggregated by `svm`.",
  "ontaps3_svm_delete_object_latency": "Average latency for DELETE object operations. ontaps3_svm_delete_object_latency is [ontaps3_svm_delete_object_latency](#ontaps3_svm_delete_object_latency) aggregated by `svm`.",
  "ontaps3_svm_delete_object_rate": "Number of DELETE object operations per second. ontaps3_svm_delete_object_rate is [ontaps3_svm_delete_object_rate](#ontaps3_svm_delete_object_rate) aggregated by `svm`.",
  "ontaps3_svm_delete_object_tagging_failed": "Number of failed DELETE object tagging operations. ontaps3_svm_delete_object_tagging_failed is [ontaps3_svm_delete_object_tagging_failed](#ontaps3_svm_delete_object_tagging_failed) aggregated by `svm`.",
  "ontaps3_svm_delete_object_tagging_failed_client_close": "Number of times DELETE object tagging operation failed because client terminated connection while the operation was still pending on server. ontaps3_svm_delete_object_tagging_failed_client_close is [ontaps3_svm_delete_object_tagging_failed_client_close](#ontaps3_svm_delete_object_tagging_failed_client_close) aggregated by `svm`.",
  "ontaps3_svm_delete_object_tagging_latency": "Average latency for DELETE object tagging operations. ontaps3_svm_delete_object_tagging_latency is [ontaps3_svm_delete_object_tagging_latency](#ontaps3_svm_delete_object_tagging_latency) aggregated by `svm`.",
  "ontaps3_svm_delete_object_tagging_rate": "Number of DELETE object tagging operations per second. ontaps3_svm_delete_object_tagging_rate is [ontaps3_svm_delete_object_tagging_rate](#ontaps3_svm_delete_object_tagging_rate) aggregated by `svm`.",
  "ontaps3_svm_delete_object_tagging_total": "Number of DELETE object tagging operations. ontaps3_svm_delete_object_tagging_total is [ontaps3_svm_delete_object_tagging_total](#ontaps3_svm_delete_object_tagging_total) aggregated by `svm`.",
  "ontaps3_svm_delete_object_total": "Number of DELETE object operations. ontaps3_svm_delete_object_total is [ontaps3_svm_delete_object_total](#ontaps3_svm_delete_object_total) aggregated by `svm`.",
  "ontaps3_svm_explicit_deny_access": "Number of times access was denied explicitly by a policy statement. ontaps3_svm_explicit_deny_access is [ontaps3_svm_explicit_deny_access](#ontaps3_svm_explicit_deny_access) aggregated by `svm`.",
  "ontaps3_svm_get_bucket_acl_failed": "Number of failed GET Bucket ACL operations. ontaps3_svm_get_bucket_acl_failed is [ontaps3_svm_get_bucket_acl_failed](#ontaps3_svm_get_bucket_acl_failed) aggregated by `svm`.",
  "ontaps3_svm_get_bucket_acl_total": "Number of GET Bucket ACL operations. ontaps3_svm_get_bucket_acl_total is [ontaps3_svm_get_bucket_acl_total](#ontaps3_svm_get_bucket_acl_total) aggregated by `svm`.",
  "ontaps3_svm_get_bucket_versioning_failed": "Number of failed Get Bucket Versioning operations. ontaps3_svm_get_bucket_versioning_failed is [ontaps3_svm_get_bucket_versioning_failed](#ontaps3_svm_get_bucket_versioning_failed) aggregated by `svm`.",
  "ontaps3_svm_get_bucket_versioning_total": "Number of Get Bucket Versioning operations. ontaps3_svm_get_bucket_versioning_total is [ontaps3_svm_get_bucket_versioning_total](#ontaps3_svm_get_bucket_versioning_total) aggregated by `svm`.",
  "ontaps3_svm_get_data": "Rate of GET object data transfers per second. ontaps3_svm_get_data is [ontaps3_svm_get_data](#ontaps3_svm_get_data) aggregated by `svm`.",
  "ontaps3_svm_get_object_acl_failed": "Number of failed GET Object ACL operations. ontaps3_svm_get_object_acl_failed is [ontaps3_svm_get_object_acl_failed](#ontaps3_svm_get_object_acl_failed) aggregated by `svm`.",
  "ontaps3_svm_get_object_acl_total": "Number of GET Object ACL operations. ontaps3_svm_get_object_acl_total is [ontaps3_svm_get_object_acl_total](#ontaps3_svm_get_object_acl_total) aggregated by `svm`.",
  "ontaps3_svm_get_object_failed": "Number of failed GET object operations. ontaps3_svm_get_object_failed is [ontaps3_svm_get_object_failed](#ontaps3_svm_get_object_failed) aggregated by `svm`.",
  "ontaps3_svm_get_object_failed_client_close": "Number of times GET object operation failed due to the case where client closed the connection while the operation was still pending on server. ontaps3_svm_get_object_failed_client_close is [ontaps3_svm_get_object_failed_client_close](#ontaps3_svm_get_object_failed_client_close) aggregated by `svm`.",
  "ontaps3_svm_get_object_lastbyte_latency": "Average last-byte latency for GET object operations. ontaps3_svm_get_object_lastbyte_latency is [ontaps3_svm_get_object_lastbyte_latency](#ontaps3_svm_get_object_lastbyte_latency) aggregated by `svm`.",
  "ontaps3_svm_get_object_latency": "Average first-byte latency for GET object operations. ontaps3_svm_get_object_latency is [ontaps3_svm_get_object_latency](#ontaps3_svm_get_object_latency) aggregated by `svm`.",
  "ontaps3_svm_get_object_rate": "Number of GET object operations per second. ontaps3_svm_get_object_rate is [ontaps3_svm_get_object_rate](#ontaps3_svm_get_object_rate) aggregated by `svm`.",
  "ontaps3_svm_get_object_tagging_failed": "Number of failed GET object tagging operations. ontaps3_svm_get_object_tagging_failed is [ontaps3_svm_get_object_tagging_failed](#ontaps3_svm_get_object_tagging_failed) aggregated by `svm`.",
  "ontaps3_svm_get_object_tagging_failed_client_close": "Number of times GET object tagging operation failed due to the case where client closed the connection while the operation was still pending on server. ontaps3_svm_get_object_tagging_failed_client_close is [ontaps3_svm_get_object_tagging_failed_client_close](#ontaps3_svm_get_object_tagging_failed_client_close) aggregated by `svm`.",
  "ontaps3_svm_get_object_tagging_latency": "Average latency for GET object tagging operations. ontaps3_svm_get_object_tagging_latency is [ontaps3_svm_get_object_tagging_latency](#ontaps3_svm_get_object_tagging_latency) aggregated by `svm`.",
  "ontaps3_svm_get_object_tagging_rate": "Number of GET object tagging operations per second. ontaps3_svm_get_object_tagging_rate is [ontaps3_svm_get_object_tagging_rate](#ontaps3_svm_get_object_tagging_rate) aggregated by `svm`.",
  "ontaps3_svm_get_object_tagging_total": "Number of GET object tagging operations. ontaps3_svm_get_object_tagging_total is [ontaps3_svm_get_object_tagging_total](#ontaps3_svm_get_object_tagging_total) aggregated by `svm`.",
  "ontaps3_svm_get_object_total": "Number of GET object operations. ontaps3_svm_get_object_total is [ontaps3_svm_get_object_total](#ontaps3_svm_get_object_total) aggregated by `svm`.",
  "ontaps3_svm_group_policy_evaluated": "Number of times group policies were evaluated. ontaps3_svm_group_policy_evaluated is [ontaps3_svm_group_policy_evaluated](#ontaps3_svm_group_policy_evaluated) aggregated by `svm`.",
  "ontaps3_svm_head_bucket_failed": "Number of failed HEAD bucket operations. ontaps3_svm_head_bucket_failed is [ontaps3_svm_head_bucket_failed](#ontaps3_svm_head_bucket_failed) aggregated by `svm`.",
  "ontaps3_svm_head_bucket_failed_client_close": "Number of times HEAD bucket operation failed due to the case where client closed the connection while the operation was still pending on server. ontaps3_svm_head_bucket_failed_client_close is [ontaps3_svm_head_bucket_failed_client_close](#ontaps3_svm_head_bucket_failed_client_close) aggregated by `svm`.",
  "ontaps3_svm_head_bucket_latency": "Average latency for HEAD bucket operations. ontaps3_svm_head_bucket_latency is [ontaps3_svm_head_bucket_latency](#ontaps3_svm_head_bucket_latency) aggregated by `svm`.",
  "ontaps3_svm_head_bucket_rate": "Number of HEAD bucket operations per second. ontaps3_svm_head_bucket_rate is [ontaps3_svm_head_bucket_rate](#ontaps3_svm_head_bucket_rate) aggregated by `svm`.",
  "ontaps3_svm_head_bucket_total": "Number of HEAD bucket operations. ontaps3_svm_head_bucket_total is [ontaps3_svm_head_bucket_total](#ontaps3_svm_head_bucket_total) aggregated by `svm`.",
  "ontaps3_svm_head_object_failed": "Number of failed HEAD Object operations. ontaps3_svm_head_object_failed is [ontaps3_svm_head_object_failed](#ontaps3_svm_head_object_failed) aggregated by `svm`.",
  "ontaps3_svm_head_object_failed_client_close": "Number of times HEAD object operation failed due to the case where client closed the connection while the operation was still pending on server. ontaps3_svm_head_object_failed_client_close is [ontaps3_svm_head_object_failed_client_close](#ontaps3_svm_head_object_failed_client_close) aggregated by `svm`.",
  "ontaps3_svm_head_object_latency": "Average latency for HEAD object operations. ontaps3_svm_head_object_latency is [ontaps3_svm_head_object_latency](#ontaps3_svm_head_object_latency) aggregated by `svm`.",
  "ontaps3_svm_head_object_rate": "Number of HEAD Object operations per second. ontaps3_svm_head_object_rate is [ontaps3_svm_head_object_rate](#ontaps3_svm_head_object_rate) aggregated by `svm`.",
  "ontaps3_svm_head_object_total": "Number of HEAD Object operations. ontaps3_svm_head_object_total is [ontaps3_svm_head_object_total](#ontaps3_svm_head_object_total) aggregated by `svm`.",
  "ontaps3_svm_initiate_multipart_upload_failed": "Number of failed Initiate Multipart Upload operations. ontaps3_svm_initiate_multipart_upload_failed is [ontaps3_svm_initiate_multipart_upload_failed](#ontaps3_svm_initiate_multipart_upload_failed) aggregated by `svm`.",
  "ontaps3_svm_initiate_multipart_upload_failed_client_close": "Number of times Initiate Multipart Upload operation failed because client terminated connection while the operation was still pending on server. ontaps3_svm_initiate_multipart_upload_failed_client_close is [ontaps3_svm_initiate_multipart_upload_failed_client_close](#ontaps3_svm_initiate_multipart_upload_failed_client_close) aggregated by `svm`.",
  "ontaps3_svm_initiate_multipart_upload_latency": "Average latency for Initiate Multipart Upload operations. ontaps3_svm_initiate_multipart_upload_latency is [ontaps3_svm_initiate_multipart_upload_latency](#ontaps3_svm_initiate_multipart_upload_latency) aggregated by `svm`.",
  "ontaps3_svm_initiate_multipart_upload_rate": "Number of Initiate Multipart Upload operations per second. ontaps3_svm_initiate_multipart_upload_rate is [ontaps3_svm_initiate_multipart_upload_rate](#ontaps3_svm_initiate_multipart_upload_rate) aggregated by `svm`.",
  "ontaps3_svm_initiate_multipart_upload_total": "Number of Initiate Multipart Upload operations. ontaps3_svm_initiate_multipart_upload_total is [ontaps3_svm_initiate_multipart_upload_total](#ontaps3_svm_initiate_multipart_upload_total) aggregated by `svm`.",
  "ontaps3_svm_input_flow_control_entry": "Number of times input flow control was entered. ontaps3_svm_input_flow_control_entry is [ontaps3_svm_input_flow_control_entry](#ontaps3_svm_input_flow_control_entry) aggregated by `svm`.",
  "ontaps3_svm_input_flow_control_exit": "Number of times input flow control was exited. ontaps3_svm_input_flow_control_exit is [ontaps3_svm_input_flow_control_exit](#ontaps3_svm_input_flow_control_exit) aggregated by `svm`.",
  "ontaps3_svm_list_buckets_failed": "Number of failed LIST Buckets operations. ontaps3_svm_list_buckets_failed is [ontaps3_svm_list_buckets_failed](#ontaps3_svm_list_buckets_failed) aggregated by `svm`.",
  "ontaps3_svm_list_buckets_failed_client_close": "Number of times LIST Bucket operation failed due to the case where client closed the connection while the operation was still pending on server. ontaps3_svm_list_buckets_failed_client_close is [ontaps3_svm_list_buckets_failed_client_close](#ontaps3_svm_list_buckets_failed_client_close) aggregated by `svm`.",
  "ontaps3_svm_list_buckets_latency": "Average latency for LIST Buckets operations. ontaps3_svm_list_buckets_latency is [ontaps3_svm_list_buckets_latency](#ontaps3_svm_list_buckets_latency) aggregated by `svm`.",
  "ontaps3_svm_list_buckets_rate": "Number of LIST Buckets operations per second. ontaps3_svm_list_buckets_rate is [ontaps3_svm_list_buckets_rate](#ontaps3_svm_list_buckets_rate) aggregated by `svm`.",
  "ontaps3_svm_list_buckets_total": "Number of LIST Buckets operations. ontaps3_svm_list_buckets_total is [ontaps3_svm_list_buckets_total](#ontaps3_svm_list_buckets_total) aggregated by `svm`.",
  "ontaps3_svm_list_object_versions_failed": "Number of failed LIST object versions operations. ontaps3_svm_list_object_versions_failed is [ontaps3_svm_list_object_versions_failed](#ontaps3_svm_list_object_versions_failed) aggregated by `svm`.",
  "ontaps3_svm_list_object_versions_failed_client_close": "Number of times LIST object versions operation failed due to the case where client closed the connection while the operation was still pending on server. ontaps3_svm_list_object_versions_failed_client_close is [ontaps3_svm_list_object_versions_failed_client_close](#ontaps3_svm_list_object_versions_failed_client_close) aggregated by `svm`.",
  "ontaps3_svm_list_object_versions_latency": "Average latency for LIST Object versions operations. ontaps3_svm_list_object_versions_latency is [ontaps3_svm_list_object_versions_latency](#ontaps3_svm_list_object_versions_latency) aggregated by `svm`.",
  "ontaps3_svm_list_object_versions_rate": "Number of LIST Object Versions operations per second. ontaps3_svm_list_object_versions_rate is [ontaps3_svm_list_object_versions_rate](#ontaps3_svm_list_object_versions_rate) aggregated by `svm`.",
  "ontaps3_svm_list_object_versions_total": "Number of LIST Object Versions operations. ontaps3_svm_list_object_versions_total is [ontaps3_svm_list_object_versions_total](#ontaps3_svm_list_object_versions_total) aggregated by `svm`.",
  "ontaps3_svm_list_objects_failed": "Number of failed LIST objects operations. ontaps3_svm_list_objects_failed is [ontaps3_svm_list_objects_failed](#ontaps3_svm_list_objects_failed) aggregated by `svm`.",
  "ontaps3_svm_list_objects_failed_client_close": "Number of times LIST objects operation failed due to the case where client closed the connection while the operation was still pending on server. ontaps3_svm_list_objects_failed_client_close is [ontaps3_svm_list_objects_failed_client_close](#ontaps3_svm_list_objects_failed_client_close) aggregated by `svm`.",
  "ontaps3_svm_list_objects_latency": "Average latency for LIST Objects operations. ontaps3_svm_list_objects_latency is [ontaps3_svm_list_objects_latency](#ontaps3_svm_list_objects_latency) aggregated by `svm`.",
  "ontaps3_svm_list_objects_rate": "Number of LIST Objects operations per second. ontaps3_svm_list_objects_rate is [ontaps3_svm_list_objects_rate](#ontaps3_svm_list_objects_rate) aggregated by `svm`.",
  "ontaps3_svm_list_objects_total": "Number of LIST Objects operations. ontaps3_svm_list_objects_total is [ontaps3_svm_list_objects_total](#ontaps3_svm_list_objects_total) aggregated by `svm`.",
  "ontaps3_svm_list_uploads_failed": "Number of failed LIST Upload operations. ontaps3_svm_list_uploads_failed is [ontaps3_svm_list_uploads_failed](#ontaps3_svm_list_uploads_failed) aggregated by `svm`.",
  "ontaps3_svm_list_uploads_failed_client_close": "Number of times LIST Upload operation failed due to the case where client closed the connection while the operation was still pending on server. ontaps3_svm_list_uploads_failed_client_close is [ontaps3_svm_list_uploads_failed_client_close](#ontaps3_svm_list_uploads_failed_client_close) aggregated by `svm`.",
  "ontaps3_svm_list_uploads_latency": "Average latency for LIST Upload operations. ontaps3_svm_list_uploads_latency is [ontaps3_svm_list_uploads_latency](#ontaps3_svm_list_uploads_latency) aggregated by `svm`.",
  "ontaps3_svm_list_uploads_rate": "Number of LIST Upload operations per second. ontaps3_svm_list_uploads_rate is [ontaps3_svm_list_uploads_rate](#ontaps3_svm_list_uploads_rate) aggregated by `svm`.",
  "ontaps3_svm_list_uploads_total": "Number of LIST Upload operations. ontaps3_svm_list_uploads_total is [ontaps3_svm_list_uploads_total](#ontaps3_svm_list_uploads_total) aggregated by `svm`.",
  "ontaps3_svm_max_cmds_per_connection": "Maximum commands pipelined at any instance on a connection. ontaps3_svm_max_cmds_per_connection is [ontaps3_svm_max_cmds_per_connection](#ontaps3_svm_max_cmds_per_connection) aggregated by `svm`.",
  "ontaps3_svm_max_connected_connections": "Maximum number of object store server connections established at one time. ontaps3_svm_max_connected_connections is [ontaps3_svm_max_connected_connections](#ontaps3_svm_max_connected_connections) aggregated by `svm`.",
  "ontaps3_svm_max_requests_outstanding": "Maximum number of object store server requests in process at one time. ontaps3_svm_max_requests_outstanding is [ontaps3_svm_max_requests_outstanding](#ontaps3_svm_max_requests_outstanding) aggregated by `svm`.",
  "ontaps3_svm_multi_delete_reqs": "Total number of object store server multiple object delete requests. ontaps3_svm_multi_delete_reqs is [ontaps3_svm_multi_delete_reqs](#ontaps3_svm_multi_delete_reqs) aggregated by `svm`.",
  "ontaps3_svm_output_flow_control_entry": "Number of output flow control was entered. ontaps3_svm_output_flow_control_entry is [ontaps3_svm_output_flow_control_entry](#ontaps3_svm_output_flow_control_entry) aggregated by `svm`.",
  "ontaps3_svm_output_flow_control_exit": "Number of times output flow control was exited. ontaps3_svm_output_flow_control_exit is [ontaps3_svm_output_flow_control_exit](#ontaps3_svm_output_flow_control_exit) aggregated by `svm`.",
  "ontaps3_svm_presigned_url_reqs": "Total number of presigned object store server URL requests. ontaps3_svm_presigned_url_reqs is [ontaps3_svm_presigned_url_reqs](#ontaps3_svm_presigned_url_reqs) aggregated by `svm`.",
  "ontaps3_svm_put_bucket_versioning_failed": "Number of failed Put Bucket Versioning operations. ontaps3_svm_put_bucket_versioning_failed is [ontaps3_svm_put_bucket_versioning_failed](#ontaps3_svm_put_bucket_versioning_failed) aggregated by `svm`.",
  "ontaps3_svm_put_bucket_versioning_total": "Number of Put Bucket Versioning operations. ontaps3_svm_put_bucket_versioning_total is [ontaps3_svm_put_bucket_versioning_total](#ontaps3_svm_put_bucket_versioning_total) aggregated by `svm`.",
  "ontaps3_svm_put_data": "Rate of PUT object data transfers per second. ontaps3_svm_put_data is [ontaps3_svm_put_data](#ontaps3_svm_put_data) aggregated by `svm`.",
  "ontaps3_svm_put_object_failed": "Number of failed PUT object operations. ontaps3_svm_put_object_failed is [ontaps3_svm_put_object_failed](#ontaps3_svm_put_object_failed) aggregated by `svm`.",
  "ontaps3_svm_put_object_failed_client_close": "Number of times PUT object operation failed due to the case where client closed the connection while the operation was still pending on server. ontaps3_svm_put_object_failed_client_close is [ontaps3_svm_put_object_failed_client_close](#ontaps3_svm_put_object_failed_client_close) aggregated by `svm`.",
  "ontaps3_svm_put_object_latency": "Average latency for PUT object operations. ontaps3_svm_put_object_latency is [ontaps3_svm_put_object_latency](#ontaps3_svm_put_object_latency) aggregated by `svm`.",
  "ontaps3_svm_put_object_rate": "Number of PUT object operations per second. ontaps3_svm_put_object_rate is [ontaps3_svm_put_object_rate](#ontaps3_svm_put_object_rate) aggregated by `svm`.",
  "ontaps3_svm_put_object_tagging_failed": "Number of failed PUT object tagging operations. ontaps3_svm_put_object_tagging_failed is [ontaps3_svm_put_object_tagging_failed](#ontaps3_svm_put_object_tagging_failed) aggregated by `svm`.",
  "ontaps3_svm_put_object_tagging_failed_client_close": "Number of times PUT object tagging operation failed because client terminated connection while the operation was still pending on server. ontaps3_svm_put_object_tagging_failed_client_close is [ontaps3_svm_put_object_tagging_failed_client_close](#ontaps3_svm_put_object_tagging_failed_client_close) aggregated by `svm`.",
  "ontaps3_svm_put_object_tagging_latency": "Average latency for PUT object tagging operations. ontaps3_svm_put_object_tagging_latency is [ontaps3_svm_put_object_tagging_latency](#ontaps3_svm_put_object_tagging_latency) aggregated by `svm`.",
  "ontaps3_svm_put_object_tagging_rate": "Number of PUT object tagging operations per second. ontaps3_svm_put_object_tagging_rate is [ontaps3_svm_put_object_tagging_rate](#ontaps3_svm_put_object_tagging_rate) aggregated by `svm`.",
  "ontaps3_svm_put_object_tagging_total": "Number of PUT object tagging operations. ontaps3_svm_put_object_tagging_total is [ontaps3_svm_put_object_tagging_total](#ontaps3_svm_put_object_tagging_total) aggregated by `svm`.",
  "ontaps3_svm_put_object_total": "Number of PUT object operations. ontaps3_svm_put_object_total is [ontaps3_svm_put_object_total](#ontaps3_svm_put_object_total) aggregated by `svm`.",
  "ontaps3_svm_request_parse_errors": "Number of request parser errors due to malformed requests. ontaps3_svm_request_parse_errors is [ontaps3_svm_request_parse_errors](#ontaps3_svm_request_parse_errors) aggregated by `svm`.",
  "ontaps3_svm_requests": "Total number of object store server requests. ontaps3_svm_requests is [ontaps3_svm_requests](#ontaps3_svm_requests) aggregated by `svm`.",
  "ontaps3_svm_requests_outstanding": "Number of object store server requests in process. ontaps3_svm_requests_outstanding is [ontaps3_svm_requests_outstanding](#ontaps3_svm_requests_outstanding) aggregated by `svm`.",
  "ontaps3_svm_root_user_access": "Number of times access was done by root user. ontaps3_svm_root_user_access is [ontaps3_svm_root_user_access](#ontaps3_svm_root_user_access) aggregated by `svm`.",
  "ontaps3_svm_server_connection_close": "Number of connection closes triggered by server due to fatal errors. ontaps3_svm_server_connection_close is [ontaps3_svm_server_connection_close](#ontaps3_svm_server_connection_close) aggregated by `svm`.",
  "ontaps3_svm_signature_v2_reqs": "Total number of object store server signature V2 requests. ontaps3_svm_signature_v2_reqs is [ontaps3_svm_signature_v2_reqs](#ontaps3_svm_signature_v2_reqs) aggregated by `svm`.",
  "ontaps3_svm_signature_v4_reqs": "Total number of object store server signature V4 requests. ontaps3_svm_signature_v4_reqs is [ontaps3_svm_signature_v4_reqs](#ontaps3_svm_signature_v4_reqs) aggregated by `svm`.",
  "ontaps3_svm_tagging": "Number of requests with tagging specified. ontaps3_svm_tagging is [ontaps3_svm_tagging](#ontaps3_svm_tagging) aggregated by `svm`.",
  "ontaps3_svm_upload_part_failed": "Number of failed Upload Part operations. ontaps3_svm_upload_part_failed is [ontaps3_svm_upload_part_failed](#ontaps3_svm_upload_part_failed) aggregated by `svm`.",
  "ontaps3_svm_upload_part_failed_client_close": "Number of times Upload Part operation failed because client terminated connection while the operation was still pending on server. ontaps3_svm_upload_part_failed_client_close is [ontaps3_svm_upload_part_failed_client_close](#ontaps3_svm_upload_part_failed_client_close) aggregated by `svm`.",
  "ontaps3_svm_upload_part_latency": "Average latency for Upload Part operations. ontaps3_svm_upload_part_latency is [ontaps3_svm_upload_part_latency](#ontaps3_svm_upload_part_latency) aggregated by `svm`.",
  "ontaps3_svm_upload_part_rate": "Number of Upload Part operations per second. ontaps3_svm_upload_part_rate is [ontaps3_svm_upload_part_rate](#ontaps3_svm_upload_part_rate) aggregated by `svm`.",
  "ontaps3_svm_upload_part_total": "Number of Upload Part operations. ontaps3_svm_upload_part_total is [ontaps3_svm_upload_part_total](#ontaps3_svm_upload_part_total) aggregated by `svm`.",
  "ontaps3_used_percent": "The used_percent metric the percentage of a bucket's total capacity that is currently being used.",
  "path_read_data": "The average read throughput in kilobytes per second read from the indicated target port by the controller.",
  "path_read_iops": "The number of I/O read operations sent from the initiator port to the indicated target port.",
  "path_read_latency": "The average latency of I/O read operations sent from this controller to the indicated target port.",
  "path_total_data": "The average throughput in kilobytes per second read and written from/to the indicated target port by the controller.",
  "path_total_iops": "The number of total read/write I/O operations sent from the initiator port to the indicated target port.",
  "path_write_data": "The average write throughput in kilobytes per second written to the indicated target port by the controller.",
  "path_write_iops": "The number of I/O write operations sent from the initiator port to the indicated target port.",
  "path_write_latency": "The average latency of I/O write operations sent from this controller to the indicated target port.",
  "plex_disk_busy": "The utilization percent of the disk. plex_disk_busy is [disk_busy](#disk_busy) aggregated by `plex`.",
  "plex_disk_capacity": "Disk capacity in MB. plex_disk_capacity is [disk_capacity](#disk_capacity) aggregated by `plex`.",
  "plex_disk_cp_read_chain": "Average number of blocks transferred in each consistency point read operation during a CP. plex_disk_cp_read_chain is [disk_cp_read_chain](#disk_cp_read_chain) aggregated by `plex`.",
  "plex_disk_cp_read_latency": "Average latency per block in microseconds for consistency point read operations. plex_disk_cp_read_latency is [disk_cp_read_latency](#disk_cp_read_latency) aggregated by `plex`.",
  "plex_disk_cp_reads": "Number of disk read operations initiated each second for consistency point processing. plex_disk_cp_reads is [disk_cp_reads](#disk_cp_reads) aggregated by `plex`.",
  "plex_disk_io_pending": "Average number of I/Os issued to the disk for which we have not yet received the response. plex_disk_io_pending is [disk_io_pending](#disk_io_pending) aggregated by `plex`.",
  "plex_disk_io_queued": "Number of I/Os queued to the disk but not yet issued. plex_disk_io_queued is [disk_io_queued](#disk_io_queued) aggregated by `plex`.",
  "plex_disk_total_data": "Total throughput for user operations per second. plex_disk_total_data is [disk_total_data](#disk_total_data) aggregated by `plex`.",
  "plex_disk_total_transfers": "Total number of disk operations involving data transfer initiated per second. plex_disk_total_transfers is [disk_total_transfers](#disk_total_transfers) aggregated by `plex`.",
  "plex_disk_user_read_blocks": "Number of blocks transferred for user read operations per second. plex_disk_user_read_blocks is [disk_user_read_blocks](#disk_user_read_blocks) aggregated by `plex`.",
  "plex_disk_user_read_chain": "Average number of blocks transferred in each user read operation. plex_disk_user_read_chain is [disk_user_read_chain](#disk_user_read_chain) aggregated by `plex`.",
  "plex_disk_user_read_latency": "Average latency per block in microseconds for user read operations. plex_disk_user_read_latency is [disk_user_read_latency](#disk_user_read_latency) aggregated by `plex`.",
  "plex_disk_user_reads": "Number of disk read operations initiated each second for retrieving data or metadata associated with user requests. plex_disk_user_reads is [disk_user_reads](#disk_user_reads) aggregated by `plex`.",
  "plex_disk_user_write_blocks": "Number of blocks transferred for user write operations per second. plex_disk_user_write_blocks is [disk_user_write_blocks](#disk_user_write_blocks) aggregated by `plex`.",
  "plex_disk_user_write_chain": "Average number of blocks transferred in each user write operation. plex_disk_user_write_chain is [disk_user_write_chain](#disk_user_write_chain) aggregated by `plex`.",
  "plex_disk_user_write_latency": "Average latency per block in microseconds for user write operations. plex_disk_user_write_latency is [disk_user_write_latency](#disk_user_write_latency) aggregated by `plex`.",
  "plex_disk_user_writes": "Number of disk write operations initiated each second for storing data or metadata associated with user requests. plex_disk_user_writes is [disk_user_writes](#disk_user_writes) aggregated by `plex`.",
  "poller_memory": "Tracks the memory usage of the poller process, including Resident Set Size (RSS), swap memory, and Virtual Memory Size (VMS).",
  "poller_memory_percent": "Indicates the percentage of memory used by the poller process relative to the total available memory.",
  "poller_status": "Indicates the operational status of the poller process, where 1 means operational and 0 means not operational.",
  "qos_concurrency": "This is the average number of concurrent requests for the workload.",
  "qos_latency": "This is the average response time for requests that were initiated by the workload.",
  "qos_ops": "This field is the workload's rate of operations that completed during the measurement interval; measured per second.",
  "qos_other_ops": "This is the rate of this workload's other operations that completed during the measurement interval.",
  "qos_policy_adaptive_absolute_min_iops": "Specifies the absolute minimum IOPS that is used as an override when the expected_iops is less than this value.",
  "qos_policy_adaptive_expected_iops": "Specifies the size to be used to calculate expected IOPS per TB.",
  "qos_policy_adaptive_labels": "This metric provides information about QosPolicyAdaptive",
  "qos_policy_adaptive_peak_iops": "Specifies the maximum possible IOPS per TB allocated based on the storage object allocated size or the storage object used size.",
  "qos_policy_fixed_labels": "This metric provides information about QosPolicyFixed",
  "qos_policy_fixed_max_throughput_iops": "Maximum throughput defined by this policy. It is specified in terms of IOPS. 0 means no maximum throughput is enforced.",
  "qos_policy_fixed_max_throughput_mbps": "Maximum throughput defined by this policy. It is specified in terms of Mbps. 0 means no maximum throughput is enforced.",
  "qos_policy_fixed_min_throughput_iops": "Minimum throughput defined by this policy. It is specified in terms of IOPS. 0 means no minimum throughput is enforced. These floors are not guaranteed on non-AFF platforms or when FabricPool tiering policies are set.",
  "qos_policy_fixed_min_throughput_mbps": "Minimum throughput defined by this policy. It is specified in terms of Mbps. 0 means no minimum throughput is enforced.",
  "qos_read_data": "This is the amount of data read per second from the filer by the workload.",
  "qos_read_io_type": "This is the percentage of read requests served from various components (such as buffer cache, ext_cache, disk, etc.).",
  "qos_read_latency": "This is the average response time for read requests that were initiated by the workload.",
  "qos_read_ops": "This is the rate of this workload's read operations that completed during the measurement interval.",
  "qos_sequential_reads": "This is the percentage of reads, performed on behalf of the workload, that were sequential.",
  "qos_sequential_writes": "This is the percentage of writes, performed on behalf of the workload, that were sequential. This counter is only available on platforms with more than 4GB of NVRAM.",
  "qos_total_data": "This is the total amount of data read/written per second from/to the filer by the workload.",
  "qos_workload_labels": "This metric provides information about QosWorkload",
  "qos_workload_max_throughput_iops": "Maximum throughput IOPs allowed for the workload.",
  "qos_workload_max_throughput_mbps": "Maximum throughput Mbps allowed for the workload.",
  "qos_workload_min_throughput_iops": "Minimum throughput IOPs allowed for the workload.",
  "qos_workload_min_throughput_mbps": "Minimum throughput Mbps allowed for the workload.",
  "qos_write_data": "This is the amount of data written per second to the filer by the workload.",
  "qos_write_latency": "This is the average response time for write requests that were initiated by the workload.",
  "qos_write_ops": "This is the workload's write operations that completed during the measurement interval; measured per second.",
  "qtree_cifs_ops": "Number of CIFS operations per second to the qtree",
  "qtree_id": "The identifier for the qtree, unique within the qtree's volume.",
  "qtree_internal_ops": "Number of internal operations generated by activites such as snapmirror and backup per second to the qtree",
  "qtree_labels": "This metric provides information about Qtree",
  "qtree_nfs_ops": "Number of NFS operations per second to the qtree",
  "qtree_other_data": "Performance metric for other I/O operations. Other I/O operations can be metadata operations, such as directory lookups and so on.",
  "qtree_other_ops": "Performance metric for other I/O operations. Other I/O operations can be metadata operations, such as directory lookups and so on.",
  "qtree_read_data": "Performance metric for read I/O operations.",
  "qtree_read_ops": "Performance metric for read I/O operations.",
  "qtree_total_data": "Performance metric aggregated over all types of I/O operations.",
  "qtree_total_ops": "Summation of NFS ops, CIFS ops, CSS ops and internal ops",
  "qtree_write_data": "Performance metric for write I/O operations.",
  "qtree_write_ops": "Performance metric for write I/O operations.",
  "quota_disk_limit": "Maximum amount of disk space, in kilobytes, allowed for the quota target (hard disk space limit). The value is -1 if the limit is unlimited.",
  "quota_disk_used": "Current amount of disk space, in kilobytes, used by the quota target.",
  "quota_disk_used_pct_disk_limit": "Current disk space used expressed as a percentage of hard disk limit.",
  "quota_disk_used_pct_soft_disk_limit": "Current disk space used expressed as a percentage of soft disk limit.",
  "quota_disk_used_pct_threshold": "Current disk space used expressed as a percentage of threshold.",
  "quota_file_limit": "Maximum number of files allowed for the quota target (hard files limit). The value is -1 if the limit is unlimited.",
  "quota_files_used": "Current number of files used by the quota target.",
  "quota_files_used_pct_file_limit": "Current number of files used expressed as a percentage of hard file limit.",
  "quota_files_used_pct_soft_file_limit": "Current number of files used expressed as a percentage of soft file limit.",
  "quota_soft_disk_limit": "soft disk space limit, in kilobytes, for the quota target. The value is -1 if the limit is unlimited.",
  "quota_soft_file_limit": "Soft file limit, in number of files, for the quota target. The value is -1 if the limit is unlimited.",
  "quota_threshold": "Disk space threshold, in kilobytes, for the quota target. The value is -1 if the limit is unlimited.",
  "raid_disk_busy": "The utilization percent of the disk. raid_disk_busy is [disk_busy](#disk_busy) aggregated by `raid`.",
  "raid_disk_capacity": "Disk capacity in MB. raid_disk_capacity is [disk_capacity](#disk_capacity) aggregated by `raid`.",
  "raid_disk_cp_read_chain": "Average number of blocks transferred in each consistency point read operation during a CP. raid_disk_cp_read_chain is [disk_cp_read_chain](#disk_cp_read_chain) aggregated by `raid`.",
  "raid_disk_cp_read_latency": "Average latency per block in microseconds for consistency point read operations. raid_disk_cp_read_latency is [disk_cp_read_latency](#disk_cp_read_latency) aggregated by `raid`.",
  "raid_disk_cp_reads": "Number of disk read operations initiated each second for consistency point processing. raid_disk_cp_reads is [disk_cp_reads](#disk_cp_reads) aggregated by `raid`.",
  "raid_disk_io_pending": "Average number of I/Os issued to the disk for which we have not yet received the response. raid_disk_io_pending is [disk_io_pending](#disk_io_pending) aggregated by `raid`.",
  "raid_disk_io_queued": "Number of I/Os queued to the disk but not yet issued. raid_disk_io_queued is [disk_io_queued](#disk_io_queued) aggregated by `raid`.",
  "raid_disk_total_data": "Total throughput for user operations per second. raid_disk_total_data is [disk_total_data](#disk_total_data) aggregated by `raid`.",
  "raid_disk_total_transfers": "Total number of disk operations involving data transfer initiated per second. raid_disk_total_transfers is [disk_total_transfers](#disk_total_transfers) aggregated by `raid`.",
  "raid_disk_user_read_blocks": "Number of blocks transferred for user read operations per second. raid_disk_user_read_blocks is [disk_user_read_blocks](#disk_user_read_blocks) aggregated by `raid`.",
  "raid_disk_user_read_chain": "Average number of blocks transferred in each user read operation. raid_disk_user_read_chain is [disk_user_read_chain](#disk_user_read_chain) aggregated by `raid`.",
  "raid_disk_user_read_latency": "Average latency per block in microseconds for user read operations. raid_disk_user_read_latency is [disk_user_read_latency](#disk_user_read_latency) aggregated by `raid`.",
  "raid_disk_user_reads": "Number of disk read operations initiated each second for retrieving data or metadata associated with user requests. raid_disk_user_reads is [disk_user_reads](#disk_user_reads) aggregated by `raid`.",
  "raid_disk_user_write_blocks": "Number of blocks transferred for user write operations per second. raid_disk_user_write_blocks is [disk_user_write_blocks](#disk_user_write_blocks) aggregated by `raid`.",
  "raid_disk_user_write_chain": "Average number of blocks transferred in each user write operation. raid_disk_user_write_chain is [disk_user_write_chain](#disk_user_write_chain) aggregated by `raid`.",
  "raid_disk_user_write_latency": "Average latency per block in microseconds for user write operations. raid_disk_user_write_latency is [disk_user_write_latency](#disk_user_write_latency) aggregated by `raid`.",
  "raid_disk_user_writes": "Number of disk write operations initiated each second for storing data or metadata associated with user requests. raid_disk_user_writes is [disk_user_writes](#disk_user_writes) aggregated by `raid`.",
  "rw_ctx_cifs_giveups": "Array of number of give-ups of CIFS ops because they rewind more than a certain threshold, categorized by their rewind reasons.",
  "rw_ctx_cifs_rewinds": "Array of number of rewinds for CIFS ops based on their reasons.",
  "rw_ctx_nfs_giveups": "Array of number of give-ups of NFS ops because they rewind more than a certain threshold, categorized by their rewind reasons.",
  "rw_ctx_nfs_rewinds": "Array of number of rewinds for NFS ops based on their reasons.",
  "rw_ctx_qos_flowcontrol": "The number of times QoS limiting has enabled stream flowcontrol.",
  "rw_ctx_qos_rewinds": "The number of restarts after a rewind because of QoS limiting.",
  "security_account_labels": "This metric provides information about SecurityAccount",
  "security_audit_destination_port": "The destination port used to forward the message.",
  "security_certificate_labels": "This metric provides information about SecurityCert",
  "security_labels": "This metric provides information about Security",
  "security_login_labels": "This metric provides information about SecurityLogin",
  "security_ssh_labels": "This metric provides information about SecuritySsh",
  "security_ssh_max_instances": "Maximum possible simultaneous connections.",
  "shelf_average_ambient_temperature": "Average temperature of all ambient sensors for shelf in Celsius.",
  "shelf_average_fan_speed": "Average fan speed for shelf in rpm.",
  "shelf_average_temperature": "Average temperature of all non-ambient sensors for shelf in Celsius.",
  "shelf_disk_count": "Disk count in a shelf.",
  "shelf_fan_labels": "This metric provides information about shelf fans.",
  "shelf_fan_rpm": "Fan Rotation Per Minute.",
  "shelf_fan_status": "Fan Operational Status.",
  "shelf_labels": "This metric provides information about Shelf",
  "shelf_max_fan_speed": "Maximum fan speed for shelf in rpm.",
  "shelf_max_temperature": "Maximum temperature of all non-ambient sensors for shelf in Celsius.",
  "shelf_min_ambient_temperature": "Minimum temperature of all ambient sensors for shelf in Celsius.",
  "shelf_min_fan_speed": "Minimum fan speed for shelf in rpm.",
  "shelf_min_temperature": "Minimum temperature of all non-ambient sensors for shelf in Celsius.",
  "shelf_module_labels": "This metric provides information about shelf module.",
  "shelf_module_status": "Displays the shelf module labels with their status.",
  "shelf_new_status": "This metric indicates a value of 1 if the shelf state is online or ok (indicating the shelf is operational) and a value of 0 for any other state (indicating the shelf is not operational).",
  "shelf_power": "Power consumed by shelf in Watts.",
  "shelf_psu_labels": "This metric provides information about shelf psu.",
  "shelf_psu_power_drawn": "Power Drawn From PSU In Watts.",
  "shelf_psu_power_rating": "Power Supply Power Ratings In Watts.",
  "shelf_psu_status": "Operational Status.",
  "shelf_sensor_labels": "This metric provides information about shelf sensor.",
  "shelf_sensor_reading": "Current Sensor Reading.",
  "shelf_sensor_status": "Operational Status.",
  "shelf_temperature_labels": "This metric provides information about shelf temperature.",
  "shelf_temperature_reading": "Temperature Reading.",
  "shelf_temperature_status": "Operational Status.",
  "shelf_voltage_labels": "This metric provides information about shelf voltage.",
  "shelf_voltage_reading": "Voltage Current Reading.",
  "shelf_voltage_status": "Operational Status.",
  "smb2_close_latency": "Average latency for SMB2_COM_CLOSE operations",
  "smb2_close_ops": "Number of SMB2_COM_CLOSE operations",
  "smb2_create_latency": "Average latency for SMB2_COM_CREATE operations",
  "smb2_create_ops": "Number of SMB2_COM_CREATE operations",
  "smb2_lock_latency": "Average latency for SMB2_COM_LOCK operations",
  "smb2_lock_ops": "Number of SMB2_COM_LOCK operations",
  "smb2_negotiate_latency": "Average latency for SMB2_COM_NEGOTIATE operations",
  "smb2_negotiate_ops": "Number of SMB2_COM_NEGOTIATE operations",
  "smb2_oplock_break_latency": "Average latency for SMB2_COM_OPLOCK_BREAK operations",
  "smb2_oplock_break_ops": "Number of SMB2_COM_OPLOCK_BREAK operations",
  "smb2_query_directory_latency": "Average latency for SMB2_COM_QUERY_DIRECTORY operations",
  "smb2_query_directory_ops": "Number of SMB2_COM_QUERY_DIRECTORY operations",
  "smb2_query_info_latency": "Average latency for SMB2_COM_QUERY_INFO operations",
  "smb2_query_info_ops": "Number of SMB2_COM_QUERY_INFO operations",
  "smb2_read_latency": "Average latency for SMB2_COM_READ operations",
  "smb2_read_ops": "Number of SMB2_COM_READ operations",
  "smb2_session_setup_latency": "Average latency for SMB2_COM_SESSION_SETUP operations",
  "smb2_session_setup_ops": "Number of SMB2_COM_SESSION_SETUP operations",
  "smb2_set_info_latency": "Average latency for SMB2_COM_SET_INFO operations",
  "smb2_set_info_ops": "Number of SMB2_COM_SET_INFO operations",
  "smb2_tree_connect_latency": "Average latency for SMB2_COM_TREE_CONNECT operations",
  "smb2_tree_connect_ops": "Number of SMB2_COM_TREE_CONNECT operations",
  "smb2_write_latency": "Average latency for SMB2_COM_WRITE operations",
  "smb2_write_ops": "Number of SMB2_COM_WRITE operations",
  "snapmirror_break_failed_count": "The number of failed SnapMirror break operations for the relationship",
  "snapmirror_break_successful_count": "The number of successful SnapMirror break operations for the relationship",
  "snapmirror_labels": "This metric provides information about SnapMirror",
  "snapmirror_lag_time": "Amount of time since the last snapmirror transfer in seconds",
  "snapmirror_last_transfer_duration": "Duration of the last SnapMirror transfer in seconds",
  "snapmirror_last_transfer_end_timestamp": "The Timestamp of the end of the last transfer",
  "snapmirror_last_transfer_size": "Size in kilobytes (1024 bytes) of the last transfer",
  "snapmirror_newest_snapshot_timestamp": "The timestamp of the newest Snapshot copy on the destination volume",
  "snapmirror_policy_labels": "This metric provides information about SnapMirrorPolicy",
  "snapmirror_resync_failed_count": "The number of failed SnapMirror resync operations for the relationship",
  "snapmirror_resync_successful_count": "The number of successful SnapMirror resync operations for the relationship",
  "snapmirror_total_transfer_bytes": "Cumulative bytes transferred for the relationship",
  "snapmirror_total_transfer_time_secs": "Cumulative total transfer time in seconds for the relationship",
  "snapmirror_update_failed_count": "The number of successful SnapMirror update operations for the relationship",
  "snapmirror_update_successful_count": "Number of Successful Updates",
  "snapshot_create_time": "Creation time of the snapshot. It is the volume access time when the snapshot was created.",
  "snapshot_labels": "This metric provides information about Snapshot",
  "snapshot_policy_labels": "This metric provides information about SnapshotPolicy",
  "snapshot_restore_size": "Size of the active file system at the time the snapshot is captured. The actual size of the snapshot also includes those blocks trapped by other snapshots.",
  "snapshot_volume_violation_count": "This metric represents the total number of snapshots that exist on volumes without being created through an applied snapshot policy.",
  "snapshot_volume_violation_total_size": "This metric captures the total size of all snapshots that were not created through an applied snapshot policy.",
  "storage_unit_avg_latency": "Performance metric aggregated over all types of I/O operations.",
  "storage_unit_labels": "This metric provides information about StorageUnit",
  "storage_unit_other_data": "Performance metric for other I/O operations. Other I/O operations can be metadata operations, such as directory lookups and so on.",
  "storage_unit_other_latency": "Performance metric for other I/O operations. Other I/O operations can be metadata operations, such as directory lookups and so on.",
  "storage_unit_other_ops": "Performance metric for other I/O operations. Other I/O operations can be metadata operations, such as directory lookups and so on.",
  "storage_unit_read_data": "Performance metric for read I/O operations.",
  "storage_unit_read_latency": "Performance metric for read I/O operations.",
  "storage_unit_read_ops": "Performance metric for read I/O operations.",
  "storage_unit_space_physical_used": "The number of bytes consumed on the disk by the storage unit, excluding snapshots.",
  "storage_unit_total_data": "Performance metric aggregated over all types of I/O operations.",
  "storage_unit_total_ops": "Performance metric aggregated over all types of I/O operations.",
  "storage_unit_write_data": "Performance metric for write I/O operations.",
  "storage_unit_write_latency": "Performance metric for write I/O operations.",
  "storage_unit_write_ops": "Performance metric for write I/O operations.",
  "support_auto_update_labels": "This metric provides information about SupportAutoUpdate",
  "support_labels": "This metric provides information about Support",
  "svm_cifs_connections": "Number of connections",
  "svm_cifs_established_sessions": "Number of established SMB and SMB2 sessions",
  "svm_cifs_latency": "Average latency for CIFS operations",
  "svm_cifs_op_count": "Array of select CIFS operation counts",
  "svm_cifs_open_files": "Number of open files over SMB and SMB2",
  "svm_cifs_ops": "Total number of CIFS operations",
  "svm_cifs_other_latency": "Performance metric for other I/O operations. Other I/O operations can be metadata operations, such as directory lookups and so on.",
  "svm_cifs_other_ops": "Performance metric for other I/O operations. Other I/O operations can be metadata operations, such as directory lookups and so on.",
  "svm_cifs_read_data": "Performance metric for read I/O operations.",
  "svm_cifs_read_latency": "Average latency for CIFS read operations",
  "svm_cifs_read_ops": "Total number of CIFS read operations",
  "svm_cifs_signed_sessions": "Number of signed SMB and SMB2 sessions.",
  "svm_cifs_total_latency": "Performance metric aggregated over all types of I/O operations.",
  "svm_cifs_total_ops": "Performance metric aggregated over all types of I/O operations.",
  "svm_cifs_write_data": "Performance metric for write I/O operations.",
  "svm_cifs_write_latency": "Average latency for CIFS write operations",
  "svm_cifs_write_ops": "Total number of CIFS write operations",
  "svm_labels": "This metric provides information about SVM",
  "svm_new_status": "This metric indicates a value of 1 if the SVM state is online (indicating the SVM is operational) and a value of 0 for any other state.",
  "svm_nfs_access_avg_latency": "Average latency of Access procedure requests. The counter keeps track of the average response time of Access requests.",
  "svm_nfs_access_total": "Total number of Access procedure requests. It is the total number of access success and access error requests.",
  "svm_nfs_backchannel_ctl_avg_latency": "Average latency of BACKCHANNEL_CTL operations.",
  "svm_nfs_backchannel_ctl_total": "Total number of BACKCHANNEL_CTL operations.",
  "svm_nfs_bind_conn_to_session_avg_latency": "Average latency of BIND_CONN_TO_SESSION operations.",
  "svm_nfs_bind_conn_to_session_total": "Total number of BIND_CONN_TO_SESSION operations.",
  "svm_nfs_close_avg_latency": "Average latency of CLOSE procedures",
  "svm_nfs_close_total": "Total number of CLOSE procedures",
  "svm_nfs_commit_avg_latency": "Average latency of Commit procedure requests. The counter keeps track of the average response time of Commit requests.",
  "svm_nfs_commit_total": "Total number of Commit procedure requests. It is the total number of Commit success and Commit error requests.",
  "svm_nfs_create_avg_latency": "Average latency of Create procedure requests. The counter keeps track of the average response time of Create requests.",
  "svm_nfs_create_session_avg_latency": "Average latency of CREATE_SESSION operations.",
  "svm_nfs_create_session_total": "Total number of CREATE_SESSION operations.",
  "svm_nfs_create_total": "Total number Create of procedure requests. It is the total number of create success and create error requests.",
  "svm_nfs_delegpurge_avg_latency": "Average latency of DELEGPURGE procedures",
  "svm_nfs_delegpurge_total": "Total number of DELEGPURGE procedures",
  "svm_nfs_delegreturn_avg_latency": "Average latency of DELEGRETURN procedures",
  "svm_nfs_delegreturn_total": "Total number of DELEGRETURN procedures",
  "svm_nfs_destroy_clientid_avg_latency": "Average latency of DESTROY_CLIENTID operations.",
  "svm_nfs_destroy_clientid_total": "Total number of DESTROY_CLIENTID operations.",
  "svm_nfs_destroy_session_avg_latency": "Average latency of DESTROY_SESSION operations.",
  "svm_nfs_destroy_session_total": "Total number of DESTROY_SESSION operations.",
  "svm_nfs_exchange_id_avg_latency": "Average latency of EXCHANGE_ID operations.",
  "svm_nfs_exchange_id_total": "Total number of EXCHANGE_ID operations.",
  "svm_nfs_free_stateid_avg_latency": "Average latency of FREE_STATEID operations.",
  "svm_nfs_free_stateid_total": "Total number of FREE_STATEID operations.",
  "svm_nfs_fsinfo_avg_latency": "Average latency of FSInfo procedure requests. The counter keeps track of the average response time of FSInfo requests.",
  "svm_nfs_fsinfo_total": "Total number FSInfo of procedure requests. It is the total number of FSInfo success and FSInfo error requests.",
  "svm_nfs_fsstat_avg_latency": "Average latency of FSStat procedure requests. The counter keeps track of the average response time of FSStat requests.",
  "svm_nfs_fsstat_total": "Total number FSStat of procedure requests. It is the total number of FSStat success and FSStat error requests.",
  "svm_nfs_get_dir_delegation_avg_latency": "Average latency of GET_DIR_DELEGATION operations.",
  "svm_nfs_get_dir_delegation_total": "Total number of GET_DIR_DELEGATION operations.",
  "svm_nfs_getattr_avg_latency": "Average latency of GetAttr procedure requests. This counter keeps track of the average response time of GetAttr requests.",
  "svm_nfs_getattr_total": "Total number of Getattr procedure requests. It is the total number of getattr success and getattr error requests.",
  "svm_nfs_getdeviceinfo_avg_latency": "Average latency of GETDEVICEINFO operations.",
  "svm_nfs_getdeviceinfo_total": "Total number of GETDEVICEINFO operations.",
  "svm_nfs_getdevicelist_avg_latency": "Average latency of GETDEVICELIST operations.",
  "svm_nfs_getdevicelist_total": "Total number of GETDEVICELIST operations.",
  "svm_nfs_getfh_avg_latency": "Average latency of GETFH procedures",
  "svm_nfs_getfh_total": "Total number of GETFH procedures",
  "svm_nfs_latency": "Average latency of NFSv3 requests. This counter keeps track of the average response time of NFSv3 requests.",
  "svm_nfs_layoutcommit_avg_latency": "Average latency of LAYOUTCOMMIT operations.",
  "svm_nfs_layoutcommit_total": "Total number of LAYOUTCOMMIT operations.",
  "svm_nfs_layoutget_avg_latency": "Average latency of LAYOUTGET operations.",
  "svm_nfs_layoutget_total": "Total number of LAYOUTGET operations.",
  "svm_nfs_layoutreturn_avg_latency": "Average latency of LAYOUTRETURN operations.",
  "svm_nfs_layoutreturn_total": "Total number of LAYOUTRETURN operations.",
  "svm_nfs_link_avg_latency": "Average latency of Link procedure requests. The counter keeps track of the average response time of Link requests.",
  "svm_nfs_link_total": "Total number Link of procedure requests. It is the total number of Link success and Link error requests.",
  "svm_nfs_lock_avg_latency": "Average latency of LOCK procedures",
  "svm_nfs_lock_total": "Total number of LOCK procedures",
  "svm_nfs_lockt_avg_latency": "Average latency of LOCKT procedures",
  "svm_nfs_lockt_total": "Total number of LOCKT procedures",
  "svm_nfs_locku_avg_latency": "Average latency of LOCKU procedures",
  "svm_nfs_locku_total": "Total number of LOCKU procedures",
  "svm_nfs_lookup_avg_latency": "Average latency of LookUp procedure requests. This shows the average time it takes for the LookUp operation to reply to the request.",
  "svm_nfs_lookup_total": "Total number of Lookup procedure requests. It is the total number of lookup success and lookup error requests.",
  "svm_nfs_lookupp_avg_latency": "Average latency of LOOKUPP procedures",
  "svm_nfs_lookupp_total": "Total number of LOOKUPP procedures",
  "svm_nfs_mkdir_avg_latency": "Average latency of MkDir procedure requests. The counter keeps track of the average response time of MkDir requests.",
  "svm_nfs_mkdir_total": "Total number MkDir of procedure requests. It is the total number of MkDir success and MkDir error requests.",
  "svm_nfs_mknod_avg_latency": "Average latency of MkNod procedure requests. The counter keeps track of the average response time of MkNod requests.",
  "svm_nfs_mknod_total": "Total number MkNod of procedure requests. It is the total number of MkNod success and MkNod error requests.",
  "svm_nfs_null_avg_latency": "Average latency of Null procedure requests.",
  "svm_nfs_null_total": "Total number of Null procedure requests. It is the total of null success and null error requests.",
  "svm_nfs_nverify_avg_latency": "Average latency of NVERIFY procedures",
  "svm_nfs_nverify_total": "Total number of NVERIFY procedures",
  "svm_nfs_open_avg_latency": "Average latency of OPEN procedures",
  "svm_nfs_open_confirm_avg_latency": "Average latency of OPEN_CONFIRM procedures",
  "svm_nfs_open_confirm_total": "Total number of OPEN_CONFIRM procedures",
  "svm_nfs_open_downgrade_avg_latency": "Average latency of OPEN_DOWNGRADE procedures",
  "svm_nfs_open_downgrade_total": "Total number of OPEN_DOWNGRADE procedures",
  "svm_nfs_open_total": "Total number of OPEN procedures",
  "svm_nfs_openattr_avg_latency": "Average latency of OPENATTR procedures",
  "svm_nfs_openattr_total": "Total number of OPENATTR procedures",
  "svm_nfs_ops": "Total number of NFSv3 procedure requests per second.",
  "svm_nfs_other_latency": "Performance metric for other I/O operations. Other I/O operations can be metadata operations, such as directory lookups and so on.",
  "svm_nfs_other_ops": "Performance metric for other I/O operations. Other I/O operations can be metadata operations, such as directory lookups and so on.",
  "svm_nfs_pathconf_avg_latency": "Average latency of PathConf procedure requests. The counter keeps track of the average response time of PathConf requests.",
  "svm_nfs_pathconf_total": "Total number PathConf of procedure requests. It is the total number of PathConf success and PathConf error requests.",
  "svm_nfs_putfh_avg_latency": "Average latency of PUTFH procedures",
  "svm_nfs_putfh_total": "Total number of PUTFH procedures",
  "svm_nfs_putpubfh_avg_latency": "Average latency of PUTPUBFH procedures",
  "svm_nfs_putpubfh_total": "Total number of PUTPUBFH procedures",
  "svm_nfs_putrootfh_avg_latency": "Average latency of PUTROOTFH procedures",
  "svm_nfs_putrootfh_total": "Total number of PUTROOTFH procedures",
  "svm_nfs_read_avg_latency": "Average latency of Read procedure requests. The counter keeps track of the average response time of Read requests.",
  "svm_nfs_read_ops": "Total observed NFSv3 read operations per second.",
  "svm_nfs_read_symlink_avg_latency": "Average latency of ReadSymLink procedure requests. The counter keeps track of the average response time of ReadSymLink requests.",
  "svm_nfs_read_symlink_total": "Total number of ReadSymLink procedure requests. It is the total number of read symlink success and read symlink error requests.",
  "svm_nfs_read_throughput": "Rate of NFSv3 read data transfers per second.",
  "svm_nfs_read_total": "Total number Read of procedure requests. It is the total number of read success and read error requests.",
  "svm_nfs_readdir_avg_latency": "Average latency of ReadDir procedure requests. The counter keeps track of the average response time of ReadDir requests.",
  "svm_nfs_readdir_total": "Total number ReadDir of procedure requests. It is the total number of ReadDir success and ReadDir error requests.",
  "svm_nfs_readdirplus_avg_latency": "Average latency of ReadDirPlus procedure requests. The counter keeps track of the average response time of ReadDirPlus requests.",
  "svm_nfs_readdirplus_total": "Total number ReadDirPlus of procedure requests. It is the total number of ReadDirPlus success and ReadDirPlus error requests.",
  "svm_nfs_readlink_avg_latency": "Average latency of READLINK procedures",
  "svm_nfs_readlink_total": "Total number of READLINK procedures",
  "svm_nfs_reclaim_complete_avg_latency": "Average latency of RECLAIM_COMPLETE operations.",
  "svm_nfs_reclaim_complete_total": "Total number of RECLAIM_COMPLETE operations.",
  "svm_nfs_release_lock_owner_avg_latency": "Average Latency of RELEASE_LOCKOWNER procedures",
  "svm_nfs_release_lock_owner_total": "Total number of RELEASE_LOCKOWNER procedures",
  "svm_nfs_remove_avg_latency": "Average latency of Remove procedure requests. The counter keeps track of the average response time of Remove requests.",
  "svm_nfs_remove_total": "Total number Remove of procedure requests. It is the total number of Remove success and Remove error requests.",
  "svm_nfs_rename_avg_latency": "Average latency of Rename procedure requests. The counter keeps track of the average response time of Rename requests.",
  "svm_nfs_rename_total": "Total number Rename of procedure requests. It is the total number of Rename success and Rename error requests.",
  "svm_nfs_renew_avg_latency": "Average latency of RENEW procedures",
  "svm_nfs_renew_total": "Total number of RENEW procedures",
  "svm_nfs_restorefh_avg_latency": "Average latency of RESTOREFH procedures",
  "svm_nfs_restorefh_total": "Total number of RESTOREFH procedures",
  "svm_nfs_rmdir_avg_latency": "Average latency of RmDir procedure requests. The counter keeps track of the average response time of RmDir requests.",
  "svm_nfs_rmdir_total": "Total number RmDir of procedure requests. It is the total number of RmDir success and RmDir error requests.",
  "svm_nfs_savefh_avg_latency": "Average latency of SAVEFH procedures",
  "svm_nfs_savefh_total": "Total number of SAVEFH procedures",
  "svm_nfs_secinfo_avg_latency": "Average latency of SECINFO procedures",
  "svm_nfs_secinfo_no_name_avg_latency": "Average latency of SECINFO_NO_NAME operations.",
  "svm_nfs_secinfo_no_name_total": "Total number of SECINFO_NO_NAME operations.",
  "svm_nfs_secinfo_total": "Total number of SECINFO procedures",
  "svm_nfs_sequence_avg_latency": "Average latency of SEQUENCE operations.",
  "svm_nfs_sequence_total": "Total number of SEQUENCE operations.",
  "svm_nfs_set_ssv_avg_latency": "Average latency of SET_SSV operations.",
  "svm_nfs_set_ssv_total": "Total number of SET_SSV operations.",
  "svm_nfs_setattr_avg_latency": "Average latency of SetAttr procedure requests. The counter keeps track of the average response time of SetAttr requests.",
  "svm_nfs_setattr_total": "Total number of Setattr procedure requests. It is the total number of Setattr success and setattr error requests.",
  "svm_nfs_setclientid_avg_latency": "Average latency of SETCLIENTID procedures",
  "svm_nfs_setclientid_confirm_avg_latency": "Average latency of SETCLIENTID_CONFIRM procedures",
  "svm_nfs_setclientid_confirm_total": "Total number of SETCLIENTID_CONFIRM procedures",
  "svm_nfs_setclientid_total": "Total number of SETCLIENTID procedures",
  "svm_nfs_symlink_avg_latency": "Average latency of SymLink procedure requests. The counter keeps track of the average response time of SymLink requests.",
  "svm_nfs_symlink_total": "Total number SymLink of procedure requests. It is the total number of SymLink success and create SymLink requests.",
  "svm_nfs_test_stateid_avg_latency": "Average latency of TEST_STATEID operations.",
  "svm_nfs_test_stateid_total": "Total number of TEST_STATEID operations.",
  "svm_nfs_throughput": "Rate of NFSv3 data transfers per second.",
  "svm_nfs_total_throughput": "Performance metric aggregated over all types of I/O operations.",
  "svm_nfs_verify_avg_latency": "Average latency of VERIFY procedures",
  "svm_nfs_verify_total": "Total number of VERIFY procedures",
  "svm_nfs_want_delegation_avg_latency": "Average latency of WANT_DELEGATION operations.",
  "svm_nfs_want_delegation_total": "Total number of WANT_DELEGATION operations.",
  "svm_nfs_write_avg_latency": "Average latency of Write procedure requests. The counter keeps track of the average response time of Write requests.",
  "svm_nfs_write_ops": "Total observed NFSv3 write operations per second.",
  "svm_nfs_write_throughput": "Rate of NFSv3 write data transfers per second.",
  "svm_nfs_write_total": "Total number of Write procedure requests. It is the total number of write success and write error requests.",
  "svm_vol_avg_latency": "Performance metric aggregated over all types of I/O operations. svm_vol_avg_latency is [volume_avg_latency](#volume_avg_latency) aggregated by `svm`.",
  "svm_vol_nfs_access_latency": "The raw data component latency in microseconds measured within ONTAP for all operations of the given type. svm_vol_nfs_access_latency is [volume_nfs_access_latency](#volume_nfs_access_latency) aggregated by `svm`.",
  "svm_vol_nfs_access_ops": "Number of operations of the given type performed on this volume. svm_vol_nfs_access_ops is [volume_nfs_access_ops](#volume_nfs_access_ops) aggregated by `svm`.",
  "svm_vol_nfs_getattr_latency": "The raw data component latency in microseconds measured within ONTAP for all operations of the given type. svm_vol_nfs_getattr_latency is [volume_nfs_getattr_latency](#volume_nfs_getattr_latency) aggregated by `svm`.",
  "svm_vol_nfs_getattr_ops": "Number of operations of the given type performed on this volume. svm_vol_nfs_getattr_ops is [volume_nfs_getattr_ops](#volume_nfs_getattr_ops) aggregated by `svm`.",
  "svm_vol_nfs_lookup_latency": "The raw data component latency in microseconds measured within ONTAP for all operations of the given type. svm_vol_nfs_lookup_latency is [volume_nfs_lookup_latency](#volume_nfs_lookup_latency) aggregated by `svm`.",
  "svm_vol_nfs_lookup_ops": "Number of operations of the given type performed on this volume. svm_vol_nfs_lookup_ops is [volume_nfs_lookup_ops](#volume_nfs_lookup_ops) aggregated by `svm`.",
  "svm_vol_nfs_other_latency": "Average time for the WAFL filesystem to process other NFS operations to the volume; not including NFS protocol request processing or network communication time which will also be included in client observed NFS request latency (Note: This is applicable only for ONTAP 9.9 and below. Harvest uses KeyPerf collector for ONTAP 9.10 onwards.). svm_vol_nfs_other_latency is [volume_nfs_other_latency](#volume_nfs_other_latency) aggregated by `svm`.",
  "svm_vol_nfs_other_ops": "Number of other NFS operations per second to the volume (Note: This is applicable only for ONTAP 9.9 and below. Harvest uses KeyPerf collector for ONTAP 9.10 onwards.). svm_vol_nfs_other_ops is [volume_nfs_other_ops](#volume_nfs_other_ops) aggregated by `svm`.",
  "svm_vol_nfs_punch_hole_latency": "Average time for the WAFL filesystem to process NFS protocol hole-punch requests to the volume (Note: This is applicable only for ONTAP 9.9 and below. Harvest uses KeyPerf collector for ONTAP 9.10 onwards.). svm_vol_nfs_punch_hole_latency is [volume_nfs_punch_hole_latency](#volume_nfs_punch_hole_latency) aggregated by `svm`.",
  "svm_vol_nfs_punch_hole_ops": "Number of NFS hole-punch requests per second to the volume (Note: This is applicable only for ONTAP 9.9 and below. Harvest uses KeyPerf collector for ONTAP 9.10 onwards.). svm_vol_nfs_punch_hole_ops is [volume_nfs_punch_hole_ops](#volume_nfs_punch_hole_ops) aggregated by `svm`.",
  "svm_vol_nfs_read_latency": "The raw data component latency in microseconds measured within ONTAP for all operations of the given type. svm_vol_nfs_read_latency is [volume_nfs_read_latency](#volume_nfs_read_latency) aggregated by `svm`.",
  "svm_vol_nfs_read_ops": "Number of operations of the given type performed on this volume. svm_vol_nfs_read_ops is [volume_nfs_read_ops](#volume_nfs_read_ops) aggregated by `svm`.",
  "svm_vol_nfs_setattr_latency": "The raw data component latency in microseconds measured within ONTAP for all operations of the given type. svm_vol_nfs_setattr_latency is [volume_nfs_setattr_latency](#volume_nfs_setattr_latency) aggregated by `svm`.",
  "svm_vol_nfs_setattr_ops": "Number of operations of the given type performed on this volume. svm_vol_nfs_setattr_ops is [volume_nfs_setattr_ops](#volume_nfs_setattr_ops) aggregated by `svm`.",
  "svm_vol_nfs_total_ops": "Number of total NFS operations per second to the volume (Note: This is applicable only for ONTAP 9.9 and below. Harvest uses KeyPerf collector for ONTAP 9.10 onwards.). svm_vol_nfs_total_ops is [volume_nfs_total_ops](#volume_nfs_total_ops) aggregated by `svm`.",
  "svm_vol_nfs_write_latency": "The raw data component latency in microseconds measured within ONTAP for all operations of the given type. svm_vol_nfs_write_latency is [volume_nfs_write_latency](#volume_nfs_write_latency) aggregated by `svm`.",
  "svm_vol_nfs_write_ops": "Number of operations of the given type performed on this volume. svm_vol_nfs_write_ops is [volume_nfs_write_ops](#volume_nfs_write_ops) aggregated by `svm`.",
  "svm_vol_other_data": "Performance metric for other I/O operations. Other I/O operations can be metadata operations, such as directory lookups and so on. svm_vol_other_data is [volume_other_data](#volume_other_data) aggregated by `svm`.",
  "svm_vol_other_latency": "Performance metric for other I/O operations. Other I/O operations can be metadata operations, such as directory lookups and so on. svm_vol_other_latency is [volume_other_latency](#volume_other_latency) aggregated by `svm`.",
  "svm_vol_other_ops": "Performance metric for other I/O operations. Other I/O operations can be metadata operations, such as directory lookups and so on. svm_vol_other_ops is [volume_other_ops](#volume_other_ops) aggregated by `svm`.",
  "svm_vol_read_data": "Performance metric for read I/O operations. svm_vol_read_data is [volume_read_data](#volume_read_data) aggregated by `svm`.",
  "svm_vol_read_latency": "Performance metric for read I/O operations. svm_vol_read_latency is [volume_read_latency](#volume_read_latency) aggregated by `svm`.",
  "svm_vol_read_ops": "Performance metric for read I/O operations. svm_vol_read_ops is [volume_read_ops](#volume_read_ops) aggregated by `svm`.",
  "svm_vol_total_data": "Performance metric aggregated over all types of I/O operations. svm_vol_total_data is [volume_total_data](#volume_total_data) aggregated by `svm`.",
  "svm_vol_total_ops": "Performance metric aggregated over all types of I/O operations. svm_vol_total_ops is [volume_total_ops](#volume_total_ops) aggregated by `svm`.",
  "svm_vol_write_data": "Performance metric for write I/O operations. svm_vol_write_data is [volume_write_data](#volume_write_data) aggregated by `svm`.",
  "svm_vol_write_latency": "Performance metric for write I/O operations. svm_vol_write_latency is [volume_write_latency](#volume_write_latency) aggregated by `svm`.",
  "svm_vol_write_ops": "Performance metric for write I/O operations. svm_vol_write_ops is [volume_write_ops](#volume_write_ops) aggregated by `svm`.",
  "svm_vscan_connections_active": "Total number of current active connections",
  "svm_vscan_dispatch_latency": "Average dispatch latency",
  "svm_vscan_scan_latency": "Average scan latency",
  "svm_vscan_scan_noti_received_rate": "Total number of scan notifications received by the dispatcher per second",
  "svm_vscan_scan_request_dispatched_rate": "Total number of scan requests sent to the Vscanner per second",
  "token_copy_bytes": "Total number of bytes copied.",
  "token_copy_failure": "Number of failed token copy requests.",
  "token_copy_success": "Number of successful token copy requests.",
  "token_create_bytes": "Total number of bytes for which tokens are created.",
  "token_create_failure": "Number of failed token create requests.",
  "token_create_success": "Number of successful token create requests.",
  "token_zero_bytes": "Total number of bytes zeroed.",
  "token_zero_failure": "Number of failed token zero requests.",
  "token_zero_success": "Number of successful token zero requests.",
  "volume_analytics_bytes_used_by_accessed_time": "Number of bytes used on-disk, broken down by date of last access.",
  "volume_analytics_bytes_used_by_modified_time": "Number of bytes used on-disk, broken down by date of last modification.",
  "volume_analytics_bytes_used_percent_by_accessed_time": "Percent used on-disk, broken down by date of last access.",
  "volume_analytics_bytes_used_percent_by_modified_time": "Percent used on-disk, broken down by date of last modification.",
  "volume_analytics_dir_bytes_used": "The actual number of bytes used on disk by this file.",
  "volume_analytics_dir_file_count": "Number of files in a directory.",
  "volume_analytics_dir_subdir_count": "Number of sub directories in a directory.",
  "volume_autosize_grow_threshold_percent": "Used space threshold which triggers autogrow. When the size-used is greater than this percent of size-total, the volume will be grown. The computed value is rounded down. The default value of this element varies from 85% to 98%, depending on the volume size. It is an error for the grow threshold to be less than or equal to the shrink threshold.",
  "volume_autosize_maximum_size": "The maximum size (in bytes) to which the volume would be grown automatically. The default value is 20% greater than the volume size. It is an error for the maximum volume size to be less than the current volume size. It is also an error for the maximum size to be less than or equal to the minimum size.",
  "volume_autosize_minimum_size": "Minimum size in bytes up to which the volume shrinks automatically. This size cannot be greater than or equal to the maximum size of volume.",
  "volume_autosize_shrink_threshold_percent": "Used space threshold size, in percentage, for the automatic shrinkage of the volume. When the amount of used space in the volume drops below this threshold, the volume automatically shrinks unless it has reached the minimum size. The volume shrinks when the 'space.used' is less than the 'shrink_threshold' percent of 'space.size'. The 'shrink_threshold' size cannot be greater than or equal to the 'grow_threshold' size.",
  "volume_avg_latency": "Performance metric aggregated over all types of I/O operations.",
  "volume_capacity_tier_footprint": "This field represents the footprint of blocks written to the volume in bytes for bin 1.",
  "volume_capacity_tier_footprint_percent": "This field represents the footprint of blocks written to the volume in bin 1 as a percentage of aggregate size.",
  "volume_clone_split_estimate": "Display an estimate of additional storage required in the underlying aggregate to perform a volume clone split operation.",
  "volume_delayed_free_footprint": "This field represents the delayed free blocks footprint in bytes. This system is used to improve delete performance by batching delete requests.",
  "volume_filesystem_size": "Filesystem size (in bytes) of the volume.  This is the total usable size of the volume, not including WAFL reserve.  This value is the same as Size except for certain SnapMirror destination volumes.  It is possible for destination volumes to have a different filesystem-size because the filesystem-size is sent across from the source volume.  This field is valid only when the volume is online.",
  "volume_guarantee_footprint": "This field represents the volume guarantee footprint in bytes. Alternatively, it is the space reserved for future writes in the volume.",
  "volume_hot_data": "Hot data size that is physically used in the volume.",
  "volume_inode_files_total": "Total user-visible file (inode) count, i.e., current maximum number of user-visible files (inodes) that this volume can currently hold.",
  "volume_inode_files_used": "Number of user-visible files (inodes) used. This field is valid only when the volume is online.",
  "volume_inode_used_percent": "volume_inode_files_used / volume_inode_total",
  "volume_labels": "This metric provides information about Volume",
  "volume_metadata_footprint": "This field represents flexible volume or flexgroup metadata in bytes.",
  "volume_new_status": "This metric indicates a value of 1 if the volume state is online (indicating the volume is operational) and a value of 0 for any other state.",
  "volume_nfs_access_latency": "The raw data component latency in microseconds measured within ONTAP for all operations of the given type.",
  "volume_nfs_access_ops": "Number of operations of the given type performed on this volume.",
  "volume_nfs_getattr_latency": "The raw data component latency in microseconds measured within ONTAP for all operations of the given type.",
  "volume_nfs_getattr_ops": "Number of operations of the given type performed on this volume.",
  "volume_nfs_lookup_latency": "The raw data component latency in microseconds measured within ONTAP for all operations of the given type.",
  "volume_nfs_lookup_ops": "Number of operations of the given type performed on this volume.",
  "volume_nfs_other_latency": "Average time for the WAFL filesystem to process other NFS operations to the volume; not including NFS protocol request processing or network communication time which will also be included in client observed NFS request latency (Note: This is applicable only for ONTAP 9.9 and below. Harvest uses KeyPerf collector for ONTAP 9.10 onwards.)",
  "volume_nfs_other_ops": "Number of other NFS operations per second to the volume (Note: This is applicable only for ONTAP 9.9 and below. Harvest uses KeyPerf collector for ONTAP 9.10 onwards.)",
  "volume_nfs_punch_hole_latency": "Average time for the WAFL filesystem to process NFS protocol hole-punch requests to the volume (Note: This is applicable only for ONTAP 9.9 and below. Harvest uses KeyPerf collector for ONTAP 9.10 onwards.)",
  "volume_nfs_punch_hole_ops": "Number of NFS hole-punch requests per second to the volume (Note: This is applicable only for ONTAP 9.9 and below. Harvest uses KeyPerf collector for ONTAP 9.10 onwards.)",
  "volume_nfs_read_latency": "The raw data component latency in microseconds measured within ONTAP for all operations of the given type.",
  "volume_nfs_read_ops": "Number of operations of the given type performed on this volume.",
  "volume_nfs_setattr_latency": "The raw data component latency in microseconds measured within ONTAP for all operations of the given type.",
  "volume_nfs_setattr_ops": "Number of operations of the given type performed on this volume.",
  "volume_nfs_total_ops": "Number of total NFS operations per second to the volume (Note: This is applicable only for ONTAP 9.9 and below. Harvest uses KeyPerf collector for ONTAP 9.10 onwards.)",
  "volume_nfs_write_latency": "The raw data component latency in microseconds measured within ONTAP for all operations of the given type.",
  "volume_nfs_write_ops": "Number of operations of the given type performed on this volume.",
  "volume_other_data": "Performance metric for other I/O operations. Other I/O operations can be metadata operations, such as directory lookups and so on.",
  "volume_other_latency": "Performance metric for other I/O operations. Other I/O operations can be metadata operations, such as directory lookups and so on.",
  "volume_other_ops": "Performance metric for other I/O operations. Other I/O operations can be metadata operations, such as directory lookups and so on.",
  "volume_overwrite_reserve_available": "amount of storage space that is currently available for overwrites, calculated by subtracting the total amount of overwrite reserve space from the amount that has already been used.",
  "volume_overwrite_reserve_total": "The size (in bytes) that is reserved for overwriting snapshotted data in an otherwise full volume. This space is usable only by space-reserved LUNs and files, and then only when the volume is full.This field is valid only when the volume is online.",
  "volume_overwrite_reserve_used": "The reserved size (in bytes) that is not available for new overwrites. The number includes both the reserved size which has actually been used for overwrites as well as the size which was never allocated in the first place. This field is valid only when the volume is online.",
  "volume_performance_tier_footprint": "This field represents the footprint of blocks written to the volume in bytes for the performance tier (bin 0).",
  "volume_performance_tier_footprint_percent": "This field represents the footprint of blocks written to the volume in bin 0 as a percentage of aggregate size.",
  "volume_read_data": "Performance metric for read I/O operations.",
  "volume_read_latency": "Performance metric for read I/O operations.",
  "volume_read_ops": "Performance metric for read I/O operations.",
  "volume_sis_compress_saved": "The total disk space (in bytes) that is saved by compressing blocks on the referenced file system.",
  "volume_sis_compress_saved_percent": "Percentage of the total disk space that is saved by compressing blocks on the referenced file system",
  "volume_sis_dedup_saved": "The total disk space (in bytes) that is saved by deduplication and file cloning.",
  "volume_sis_dedup_saved_percent": "Percentage of the total disk space that is saved by deduplication and file cloning.",
  "volume_sis_total_saved": "Total space saved (in bytes) in the volume due to deduplication, compression, and file cloning.",
  "volume_sis_total_saved_percent": "Percentage of total disk space that is saved by compressing blocks, deduplication and file cloning.",
  "volume_size": "Physical size of the volume, in bytes. The minimum size for a FlexVol volume is 20MB and the minimum size for a FlexGroup volume is 200MB per constituent. The recommended size for a FlexGroup volume is a minimum of 100GB per constituent. For all volumes, the default size is equal to the minimum size.",
  "volume_size_available": "The size (in bytes) that is still available in the volume. This field is valid only when the volume is online.",
  "volume_size_total": "Total usable size (in bytes) of the volume, not including WAFL reserve or volume snapshot reserve.  If the volume is restricted or offline, a value of 0 is returned.",
  "volume_size_used": "Number of bytes used in the volume.  If the volume is restricted or offline, a value of 0 is returned.",
  "volume_size_used_percent": "percentage of utilized storage space in a volume relative to its total capacity",
  "volume_snaplock_labels": "This metric provides information about VolumeSnaplock",
  "volume_snapshot_count": "Number of snapshots in the volume.",
  "volume_snapshot_reserve_available": "The size (in bytes) that is available for Snapshot copies inside the Snapshot reserve. This value is zero if Snapshot spill is present. For 'none' guaranteed volumes, this may get reduced due to less available space in the aggregate. This parameter is not supported on Infinite Volumes.",
  "volume_snapshot_reserve_percent": "The percentage of volume disk space that has been set aside as reserve for snapshot usage.",
  "volume_snapshot_reserve_size": "The size (in bytes) in the volume that has been set aside as reserve for snapshot usage.",
  "volume_snapshot_reserve_used": "amount of storage space currently used by a volume's snapshot reserve, which is calculated by subtracting the snapshot reserve available space from the snapshot reserve size.",
  "volume_snapshot_reserve_used_percent": "Percentage of the volume reserved for snapshots that has been used. Note that in some scenarios, it is possible to pass 100% of the space allocated.",
  "volume_snapshots_size_available": "Total free space (in bytes) available in the volume and the snapshot reserve. If this value is 0 or negative, a new snapshot cannot be created.",
  "volume_snapshots_size_used": "The size (in bytes) that is used by snapshots in the volume.",
  "volume_space_expected_available": "The size (in bytes) that should be available for the volume irrespective of available size in the aggregate.This is same as size-available for 'volume' guaranteed volumes.For 'none' guaranteed volumes this value is calculated as if the aggregate has enough backing disk space to fully support the volume's size.Similar to the size-available property, this does not include Snapshot reserve.This count gets reduced if snapshots consume space above Snapshot reserve threshold.This parameter is not supported on Infinite Volumes.",
  "volume_space_logical_available": "The size (in bytes) that is logically available in the volume.This is the amount of free space available considering space saved by the storage efficiency features as being used.This does not include Snapshot reserve.This parameter is not supported on FlexGroups or Infinite Volumes.",
  "volume_space_logical_used": "The size (in bytes) that is logically used in the volume.This value includes all the space saved by the storage efficiency features along with the physically used space.This does not include Snapshot reserve but does consider Snapshot spill.This parameter is not supported on FlexGroups or Infinite Volumes.",
  "volume_space_logical_used_by_afs": "The size (in bytes) that is logically used by the active filesystem of the volume.This value differs from 'logical-used' by the amount of Snapshot spill that exceeds Snapshot reserve.This parameter is not supported on FlexGroups or Infinite Volumes.",
  "volume_space_logical_used_by_snapshots": "The size (in bytes) that is logically used across all Snapshot copies in the volume. This value differs from 'size-used-by-snapshots' by the space saved by the storage efficiency features across the Snapshot copies.This parameter is not supported on FlexGroups or Infinite Volumes.",
  "volume_space_logical_used_percent": "Percentage of the logical used size of the volume.This parameter is not supported on FlexGroups or Infinite Volumes.",
  "volume_space_performance_tier_inactive_user_data": "The size that is physically used in the performance tier of the volume and has a cold temperature. This parameter is only supported if the volume is in an aggregate that is either attached to object store or could be attached to an object store.",
  "volume_space_performance_tier_inactive_user_data_percent": "The size (in percent) that is physically used in the performance tier of the volume and has a cold temperature. This parameter is only supported if the volume is in an aggregate that is either attached to object store or could be attached to an object store.",
  "volume_space_physical_used": "The size (in bytes) that is physically used in the volume.This differs from 'total-used' space by the space that is reserved for future writes.The value includes blocks in use by Snapshot copies.This field is valid only if the volume is online.",
  "volume_space_physical_used_percent": "The size (in percent) that is physically used in the volume.The percentage is based on volume size including the space reserved for Snapshot copies.This field is valid only if the volume is online.",
  "volume_tags": "Displays tags at the volume level.",
  "volume_top_clients_read_data": "This metric measures the amount of data read by the top clients to a specific volume.",
  "volume_top_clients_read_ops": "This metric tracks the number of read operations performed by the top clients on a specific volume.",
  "volume_top_clients_write_data": "This metric measures the amount of data written by the top clients to a specific volume.",
  "volume_top_clients_write_ops": "This metric tracks the number of write operations performed by the top clients on a specific volume.",
  "volume_top_files_read_data": "This metric measures the amount of data read from the files of a specific volume.",
  "volume_top_files_read_ops": "This metric tracks the number of read operations performed on the files of a specific volume.",
  "volume_top_files_write_data": "This metric measures the amount of data written to the top files of a specific volume.",
  "volume_top_files_write_ops": "This metric tracks the number of write operations performed on the files of a specific volume.",
  "volume_total_data": "This metric represents the total amount of data that has been read from and written to a specific volume.",
  "volume_total_footprint": "This field represents the total footprint in bytes.",
  "volume_total_metadata_footprint": "This field represents the total metadata footprint in bytes.",
  "volume_total_ops": "Performance metric aggregated over all types of I/O operations.",
  "volume_write_data": "Performance metric for write I/O operations.",
  "volume_write_latency": "Performance metric for write I/O operations.",
  "volume_write_ops": "Performance metric for write I/O operations.",
  "vscan_labels": "This metric provides information about Vscan",
  "vscan_scan_latency": "Average scan latency",
  "vscan_scan_request_dispatched_rate": "Total number of scan requests sent to the scanner per second",
  "vscan_scanner_stats_pct_cpu_used": "Percentage CPU utilization on scanner calculated over the last 15 seconds.",
  "vscan_scanner_stats_pct_mem_used": "Percentage RAM utilization on scanner calculated over the last 15 seconds.",
  "vscan_scanner_stats_pct_network_used": "Percentage network utilization on scanner calculated for the last 15 seconds.",
  "wafl_avg_msg_latency": "Average turnaround time for WAFL messages in milliseconds.",
  "wafl_avg_non_wafl_msg_latency": "Average turnaround time for non-WAFL messages in milliseconds.",
  "wafl_avg_repl_msg_latency": "Average turnaround time for replication WAFL messages in milliseconds.",
  "wafl_cp_count": "Array of counts of different types of Consistency Points (CP).",
  "wafl_cp_phase_times": "Array of percentage time spent in different phases of Consistency Point (CP).",
  "wafl_memory_free": "The current WAFL memory available in the system.",
  "wafl_memory_used": "The current WAFL memory used in the system.",
  "wafl_msg_total": "Total number of WAFL messages per second.",
  "wafl_non_wafl_msg_total": "Total number of non-WAFL messages per second.",
  "wafl_read_io_type": "Percentage of reads served from buffer cache, external cache, or disk.",
  "wafl_reads_from_cache": "WAFL reads from cache.",
  "wafl_reads_from_cloud": "WAFL reads from cloud storage.",
  "wafl_reads_from_cloud_s2c_bin": "WAFL reads from cloud storage via s2c bin.",
  "wafl_reads_from_disk": "WAFL reads from disk.",
  "wafl_reads_from_ext_cache": "WAFL reads from external cache.",
  "wafl_reads_from_fc_miss": "WAFL reads from remote volume for fc_miss.",
  "wafl_reads_from_pmem": "Wafl reads from persistent mmeory.",
  "wafl_reads_from_ssd": "WAFL reads from SSD.",
  "wafl_repl_msg_total": "Total number of replication WAFL messages per second.",
  "wafl_total_cp_msecs": "Milliseconds spent in Consistency Point (CP).",
  "wafl_total_cp_util": "Percentage of time spent in a Consistency Point (CP)."
}

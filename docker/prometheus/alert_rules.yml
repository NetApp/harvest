# Example Harvest alerts

groups:
- name: Harvest Rules
  rules:

  # Alert for any instance that is unreachable for >5 minutes.
  - alert: InstanceDown
    expr: up == 0
    for: 5m
    labels:
      severity: "critical"
    annotations:
      summary: "Endpoint [{{ $labels.instance }}] down"
      description: "[{{ $labels.instance }}] of job [{{ $labels.job }}] has been down for more than 5 minutes."

  # Alert for any instance that has a volume used percentage > 90%
  - alert: Volume Used Percentage Breach
    expr: volume_size_used_percent > 90
    for: 5m
    labels:
      severity: "critical"
    annotations:
      summary: "Volume [{{ $labels.volume }}] is [{{$value}}%] used"
      description: "Volume [{{ $labels.volume }}] is [{{$value}}%] used"


  # Alert for offline volume
  - alert: Volume state offline
    expr: volume_labels{state="offline"} == 1
    for: 5m
    labels:
      severity: "critical"
    annotations:
      summary: "Volume [{{ $labels.volume  }}] is offline"
      description: "Volume [{{ $labels.volume  }}] is offline"

    # Alert for offline aggregate
  - alert: Aggregate state is not online
    expr: aggr_labels{state!="online"} == 1
    for: 5m
    labels:
      severity: "critical"
    annotations:
      summary: "Aggregate [{{ $labels.aggr }}] state is [{{ $labels.state }}]"
      description: "Aggregate [{{ $labels.aggr }}] state is [{{ $labels.state }}]"

    # Alert for disk failure
  - alert: Disk failure
    expr: disk_labels{failed="true"} == 1
    for: 5m
    labels:
      severity: "critical"
    annotations:
      summary: "Disk [{{ $labels.disk }}] is in failure state"
      description: "Disk [{{ $labels.disk }}] is in failure state"


    # Alert for node nfs latency
  - alert: Node nfs latency is high
    expr: node_nfs_latency > 1000
    for: 5m
    labels:
      severity: "critical"
    annotations:
      summary: "Node [{{ $labels.node }}] has [{{$value}}] nfs latency"
      description: "Node [{{ $labels.node }}] has [{{$value}}] nfs latency"

    # Snapmirror lag time is high
  - alert: Snapmirror lag time is high
    expr: snapmirror_lag_time > 3600
    for: 1m
    labels:
      severity: "critical"
    annotations:
      summary: "Snapmirror [{{ $labels.relationship_id }}] has [{{$value}}] lag time (in secs)"
      description: "Snapmirror [{{ $labels.relationship_id }}] has [{{$value}}] lag time (in secs)"


- name: Harvest Ems Alert
  rules:

  # Alert for Anti-ransomware state change ems
  - alert: Anti-ransomware state was changed volume
    expr: present_over_time(ems_events{message="arw.volume.state"} [15m] ) == 1
    labels:
      severity: "error"
    annotations:
      summary: "Anti-ransomware state was changed to [{{ $labels.op }}] for Volume uuid [{{ $labels.volumeuuid }}]."
      description: "Anti-ransomware state was changed to [{{ $labels.op }}] for Volume uuid [{{ $labels.volumeuuid }}]."

  # Alert for Anti-ransomware state change ems
  - alert: Anti-ransomware state was changed svm
    expr: present_over_time(ems_events{message="arw.vserver.state"} [15m] ) == 1
    labels:
      severity: "error"
    annotations:
      summary: "Anti-ransomware state was changed to [{{ $labels.op }}] for SVM name [{{ $labels.vserverName }}]."
      description: "Anti-ransomware state was changed to [{{ $labels.op }}] for SVM name [{{ $labels.vserverName }}]."

  # Alert for Call-home arw message ems
  - alert: Call-home arw message received
    expr: present_over_time(ems_events{message="callhome.arw.activity.seen"} [15m] ) == 1
    labels:
      severity: "error"
    annotations:
      summary: "Call-home arw message for Volume uuid [{{ $labels.volume_uuid }}]."
      description: "Call-home arw message for Volume uuid [{{ $labels.volume_uuid }}]."

  # Alert for Call-home battery low bookend ems - will be resolved by nvram battery charging normal
  - alert: Call-home battery low message received
    expr: (max by(node_uuid) (last_over_time(timestamp(ems_events{message="callhome.battery.low"})[30m:])) - max by(node_uuid) (last_over_time(timestamp(ems_events{message="nvram.battery.charging.normal"})[30m:])) or group by (node_uuid) (last_over_time(timestamp(ems_events{message="callhome.battery.low"})[30m:]) unless on (node_uuid) last_over_time(timestamp(ems_events{message="nvram.battery.charging.normal"})[30m:]))) > 0
    labels:
      severity: "error"
    annotations:
      summary: "Call home BATTERY_LOW message for Node uuid [{{ $labels.node_uuid }}]."
      description: "Call home BATTERY_LOW message for Node uuid [{{ $labels.node_uuid }}]."

  # Alert for Call-home hainterconnect down ems
  - alert: Call-home ha interconnect message received
    expr: present_over_time(ems_events{message="callhome.hainterconnect.down"} [15m] ) == 1
    labels:
      severity: "error"
    annotations:
      summary: "Call-home ha interconnect message for Node uuid [{{ $labels.node_uuid }}]."
      description: "Call-home ha interconnect message for Node uuid [{{ $labels.node_uuid }}]."

  # For testing same ems with multi-state value
  # Alert for state change ems, disable state - will be resolved by enable state
  - alert: Anti-ransomware state changed for volume
    expr: (max by (volumeuuid) (last_over_time(timestamp(ems_events{message="arw.volume.state", op=~"disabled|any"})[30m:])) - max by (volumeuuid) (last_over_time(timestamp(ems_events{message="arw.volume.state", op=~"enabled"})[30m:])) or group by (volumeuuid) (last_over_time(timestamp(ems_events{message="arw.volume.state", op=~"disabled|any"})[30m:]) unless on (volumeuuid) last_over_time(timestamp(ems_events{message="arw.volume.state", op=~"enabled"})[30m:]))) > 0
    labels:
      severity: "error"
    annotations:
      summary: "Anti-ransomware state was changed to [{{ $labels.op }}] for Volume uuid [{{ $labels.volumeuuid }}]."
      description: "Anti-ransomware state was changed to [{{ $labels.op }}] for Volume uuid [{{ $labels.volumeuuid }}]."
